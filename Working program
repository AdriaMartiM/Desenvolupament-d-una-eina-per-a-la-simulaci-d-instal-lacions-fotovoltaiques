import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches 
import geopandas as gpd
import pvlib
from typing import Optional
from typing import List, Tuple
from shapely.geometry import Polygon, box, Point
from shapely.affinity import rotate, translate, scale
from shapely.ops import unary_union
from matplotlib.patches import Polygon as MplPolygon
from scipy.spatial import KDTree
from pvlib import solarposition
from pvlib import pvsystem, modelchain, temperature, location, iotools
from pvlib.location import Location
from pvlib.modelchain import ModelChain
from pvlib.pvsystem import PVSystem, retrieve_sam
from pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS
from joblib import Parallel, delayed
from concurrent.futures import ProcessPoolExecutor
from pvlib.modelchain import ModelChain
import random
from pvlib.iotools import get_pvgis_tmy
import gc
import os
from scipy.interpolate import Rbf
from scipy.spatial import cKDTree
from matplotlib.colors import LinearSegmentedColormap
from matplotlib.colors import Normalize
from matplotlib import cm
import time
import glob
import re
import folium
import json
import topojson 
from folium.features import TopoJson
from branca.colormap import LinearColormap # Importaci√≥n correcta
import matplotlib.pyplot as plt
from io import BytesIO
import base64

class Cluster:
    """ Aquesta clase serveix per inicialitzar totes les cariables que ens faran falta mes endevant, d'aquesta manera
        tindrem la info del cluster en tot moment.
        Esquema que fa la clase?
            -Carrega l'arxiu gpkg i assigna i treu totes les varibles dessitjades
            -Convertim la info de la geometr√≠a en coordenades per un √∫s m√©s facil
            -Creem una def per tindre el plot del gpkg i poder validar la informaci√≥
            -Carreguem l'arxiu CSV i obtenim l'informaci√≥ relelvant
            -Obteinim el nombre de punts totals
            -Creem un plot per les dades
        No hi ha cap plot ben fet doncs ja tinc un altre arxiu m√©s centrat a fer plots de grafiques
    """
    def __init__(self, cluster_id: int, gpkg_path: str, csv_path: str, lat: float, lon: float, simulation_time: float, time_zone: str, panel_w=1.0, panel_l=1.7, sep_row=0.05, base_dir: str=""):
        self.id = cluster_id
        self.gpkg_path = gpkg_path
        self.csv_path = csv_path
        self.lat = lat
        self.lon = lon 
        self.simulation_time = simulation_time
        self.time_zone = time_zone
        self.panel_w = panel_w
        self.panel_l = panel_l
        self.sep_row = sep_row 
        self.base_dir = base_dir

        self.azimuth = None
        self.tilt = None
        self.silhouette = None
        self.geometry = None
        self.coordinates = []
        self.points = []
        
        self._load_gpkg_data()
        self._load_csv_data()

    def _load_gpkg_data(self): #Carga el GPKG i extreu les dades del cluster
        try:
            gdf = gpd.read_file(self.gpkg_path)
            
            if 'cluster' in gdf.columns:
                cluster_data = gdf[gdf['cluster'] == self.id].iloc[0]
            else:
                cluster_data = gdf.iloc[self.id - 1]  
            
            # Asignaci√≥ corecta de les propietats
            self.azimuth = float(cluster_data['azimuth'])
            self.tilt = float(cluster_data['tilt'])
            self.silhouette = float(cluster_data['silhouette'])
            self.geometry = cluster_data.geometry
            self.coordinates = self._extract_coords(cluster_data.geometry)
            
            # En cas d'error, mostrar on es troba el problema
        except Exception as e:
            available_cols = gdf.columns.tolist() if 'gdf' in locals() else []
            raise ValueError(
                f"Error cargando GPKG para cluster {self.id}.\n"
                f"Columnas disponibles: {available_cols}\n"
                f"Error: {str(e)}"
            )

    def _extract_coords(self, geom): #Convierte la geometr√≠a a coordenades
    
        if geom.geom_type == 'MultiPolygon':
            return [list(poly.exterior.coords) for poly in geom.geoms]
        elif geom.geom_type == 'Polygon':
            return [list(geom.exterior.coords)]
        return []

    def mostrar_dades_gpkg(self): #Mostrem les dades del GPKG
        print("\n=== Dades del GPKG ===")
        print(f"Cluster ID: {self.id}")
        print(f"Azimuth: {self.azimuth}¬∞")
        print(f"Silhouette score: {self.silhouette}")
        print(f"Tilt: {self.tilt}¬∞")
        if self.coordinates:
            print(f"Primeres coordenades: {self.coordinates[0][:2]}... (total: {len(self.coordinates[0])} punts)")

    def _load_csv_data(self): #Carrega el CSV i extreu les dades dels punts
        try:
            df = pd.read_csv(self.csv_path)
            self.points = [{
                'x': row[0],
                'y': row[1],
                'z': row[2],
                'shading': row[3:363].tolist()
            } for _, row in df.iterrows()]
        except Exception as e:
            raise ValueError(f"Error cargando CSV: {str(e)}")

    def get_point_count(self) -> int: #Retorna el nombre de punts
        return len(self.points)

    def mostrar_dades_csv(self, num_points: Optional[int] = None): #Mostrem els punts del CSV
        points_to_show = self.points[:num_points] if num_points else self.points
        for i, point in enumerate(points_to_show, 1):
            print(f"Punt {i}: ({point['x']}, {point['y']}, {point['z']})")
            print(f"  Perfil d'ombra (5 valors): {point['shading'][:5]}...")

    def _crear_carpeta_resultats(self) -> str:
            """
            Crea la carpeta 'Resultats' dins la carpeta de l'edifici.
            """
            building_root = os.path.dirname(os.path.dirname(self.gpkg_path))
            results_dir = os.path.join(building_root, "Resultats")
            os.makedirs(results_dir, exist_ok=True)
            return results_dir


class SolarPanelOptimizer:
    """ Aquesta classe t√© com a principal obectiu optimitzar la posici√≥ de les plaques solars dintre un cluster concret
        Que fa aquesta classe? (Aix√≤ √©s l'esquema principal el programa √©s millor explicat despr√©s)
            -Rotem els panels perque quadrin amb el cluster (Tant azimut com tilt)
            -Creem una def que inicalitza una panell en coordenades x,y
            -Mirem si la posici√≥ t√© sentit i no trenca cap regla
            -Busca l'inici del cluster, donant un input incial que indica per on comen√ßar
            -Fa avan√ßar la linea desde la posici√≥ triada
            -Calcula quanta superficie hem tapat
            -Optimitza el proces per aconseguir el millor resultat
            -Plot sencill per comprovar que funciona
    """
    def __init__(self, cluster):
        self.cluster = cluster
        self.geometry = cluster.geometry  
        self.tilt = cluster.tilt          
        self.shading_data = cluster.points 

        self.panel_w = cluster.panel_w
        self.panel_l = cluster.panel_l
        self.sep_row = cluster.sep_row  

        # 1Ô∏è‚É£ Crear primer el panell base (sense rotaci√≥)
        self.base_panel = box(-self.panel_w / 2, -self.panel_l / 2, self.panel_w / 2, self.panel_l / 2)

        # 2Ô∏è‚É£ Assignar el azimut inicial del cluster
        self.azimuth = cluster.azimuth

        # 3Ô∏è‚É£ Recalcula l'azimut si tilt < 5
        self.tilt_or_flat()

        # 4Ô∏è‚É£ Ara s√≠ podem rotar el panell segons l'azimut final
        self.rotated_panel = self._rotate_panel(self.base_panel)

        # 5Ô∏è‚É£ Direccions principals
        self.main_dir = np.array([np.cos(np.radians(self.azimuth)), 
                                np.sin(np.radians(self.azimuth))])
        self.perp_dir = np.array([-self.main_dir[1], self.main_dir[0]])

        self.covered_area = None

    def tilt_or_flat(self):
        tilt = getattr(self.cluster, 'tilt', 0)
        if tilt < 5:
            print("[INFO] Tilt <5¬∞ - Calculando azimut √≥ptimo...")
            original_az = self.azimuth
            self.azimuth = self._azimut_personalitzat()
            print(f"[RESULTADO] Azimut cambiado de {original_az}¬∞ a {self.azimuth}¬∞")
        else:
            print(f"[INFO] Tilt = {tilt}¬∞ - Usando azimut del cluster: {self.azimuth}¬∞")
        
        # üîÑ Conversi√≥n de azimut GIS ‚Üí sistema matem√°tico de shapely
        self.azimuth = (90 - self.azimuth) % 360
        
        # Actualizar direcciones
        self.main_dir = np.array([np.cos(np.radians(self.azimuth)), 
                                np.sin(np.radians(self.azimuth))])
        self.perp_dir = np.array([-self.main_dir[1], self.main_dir[0]])
        
        # Rotar panel seg√∫n azimut convertido
        self.rotated_panel = self._rotate_panel(self.base_panel)

    def _azimut_personalitzat(self) -> float:
        """Determina el azimut √≥ptimo considerando el perfil de sombras"""
        # 1. Orientaci√≥n base por hemisferio
        az_base = 180.0 if self.cluster.lat >= 0 else 0.0

        # 2. Si no hay datos de sombreado, usar orientaci√≥n base
        if not hasattr(self.cluster, 'points') or len(self.cluster.points) == 0:
            print("[AVISO] No hay datos de sombreado. Usando orientaci√≥n base.")
            return az_base

        # 3. Calcular perfil de sombra promedio
        shading_data = np.array([p['shading'] for p in self.cluster.points])
        shading_profile = np.mean(shading_data, axis=0)

        # Funci√≥n auxiliar: sombreado medio en ventana ¬±30¬∞
        def sombra_media(az):
            az = int(az) % 360
            idx_ini = (az - 30) % 360
            idx_fin = (az + 30) % 360
            if idx_ini < idx_fin:
                return np.mean(shading_profile[idx_ini:idx_fin])
            else:  # ventana que cruza 0¬∞
                return np.mean(np.concatenate((shading_profile[idx_ini:], shading_profile[:idx_fin])))

        # 4. Definir rango permitido (¬±30¬∞ alrededor del az_base)
        az_min = (az_base - 30) % 360
        az_max = (az_base + 30) % 360

        # 5. Generar candidatos cada 5¬∞ en ese rango
        candidatos = []
        for offset in range(-30, 31, 5):
            az_candidate = (az_base + offset) % 360
            candidatos.append(az_candidate)

        # 6. Evaluar todos los candidatos y quedarse con el mejor
        best_az = az_base
        best_shade = sombra_media(az_base)

        for az in candidatos:
            current_shade = sombra_media(az)
            if current_shade < best_shade:
                best_az = az
                best_shade = current_shade

        
        print(f"[OPTIM] Azimut √≥ptimo: {best_az:.1f}¬∞")
        return (90 - best_az) % 360

    def _rotate_panel(self, panel):    #Rota el panel en direcci√≥ al azimur i al tilt del cluster
        panel = rotate(panel, self.azimuth, origin=(0,0))   #Aixi les plaques estan orientades en direcci√≥ al cluster
        return scale(panel, 1, np.cos(np.radians(self.tilt)), origin=(0,0)) #reduim les dimensions al tilt per simular el 3D en un pla 2D

    def _create_panel(self, x, y):                  #Serveix per crear un panel en una posicio x,y per especificar
        return translate(self.rotated_panel, x, y)  #Aplica la funci√≥ de rotar al panel en la direccio x,y

    def _is_valid_placement(self, panel, existing_panels):
       
        # 1a comprovaci√≥: El panel ha d'estar dins dels l√≠mits del cluster
        if not self.geometry.contains(panel):               
            return False  # El panel est√† fora dels l√≠mits permessos
            
        # 2a comprovaci√≥: Verificaci√≥ r√†pida de solapament 
        panel_bounds = panel.bounds  # Obtenim els l√≠mits del rectangle que cont√© el panel
        for p in existing_panels:
            p_bounds = p.bounds  # L√≠mits dels panells existents
            
            # Comprovem si els rectangles es solapen
            if (panel_bounds[0] < p_bounds[2] and panel_bounds[2] > p_bounds[0] and
                panel_bounds[1] < p_bounds[3] and panel_bounds[3] > p_bounds[1]):
                # Si els rectangles es solapen, verifiquem amb precisi√≥
                if panel.intersects(p):
                    return False  # Hi ha solapament geom√®tric
        
        # 3a comprovaci√≥: Respectar la dist√†ncia m√≠nima entre panells (self.sep)
        if existing_panels:
            min_distance = min(panel.distance(p) for p in existing_panels)  # Dist√†ncia m√≠nima a qualsevol panel existent
            if min_distance < self.sep_row:
                return False  # Violaci√≥ de la separaci√≥ m√≠nima
                
        # Si passa totes les comprovacions, la posici√≥ √©s v√†lida
        return True

    def _get_edge_start_points(self, num_points=6):
        """
        Genera punts inicials al llarg d'una l√≠nia que travessa el cluster
        en la direcci√≥ principal (azimutal), des de banda a banda.
        """
        # Centroid del cluster
        centroid = self.geometry.centroid
        center = np.array([centroid.x, centroid.y])

        # Direcci√≥ principal i perpendicular
        main_vec = self.main_dir / np.linalg.norm(self.main_dir)

        # Trobar el punt d'inici i final del segment dins del polygon
        # Avancem cap endavant fins sortir del polygon
        max_dist = max(self.geometry.bounds[2]-self.geometry.bounds[0],
                    self.geometry.bounds[3]-self.geometry.bounds[1]) * 2  # suficient llarg
        start_pos = center.copy()
        while self.geometry.contains(Point(start_pos)):
            start_pos -= main_vec  # mou cap enrere fins fora
        start_pos += main_vec  # retrocedim un pas dins

        end_pos = center.copy()
        while self.geometry.contains(Point(end_pos)):
            end_pos += main_vec
        end_pos -= main_vec  # pas dins

        # Generem punts distribu√Øts entre start_pos i end_pos
        points = [start_pos + (end_pos - start_pos) * i / (num_points-1) for i in range(num_points)]

        return points

    def _place_systematic_row(self, start_point, existing_panels):
        """Versi√≥ que permet comen√ßar files des de fora del cluster"""
        panels = []
        step_size = (self.panel_w + self.sep_row)
        step_vector = step_size * self.main_dir
        
        # Versi√≥ cap endavant - permet comen√ßar des de fora
        pos = np.array(start_point, dtype=np.float64)
        forward_panels = []
        outside_cluster = not self.geometry.contains(Point(pos))
        reentry_attempts = 0
        max_reentry_attempts = 50  # Augmentem els intents per tornar a entrar
        
        for i in range(100):  # Augmentem el l√≠mit d'iteracions
            panel = self._create_panel(pos[0], pos[1])
            
            # Comprovem si est√† dins del cluster i √©s v√†lid
            if self.geometry.contains(Point(pos)):
                if self._is_valid_placement(panel, existing_panels + forward_panels):
                    forward_panels.append(panel)
                    if outside_cluster:
                        outside_cluster = False
                    reentry_attempts = 0
                # Si est√† dins per√≤ no √©s v√†lid (col¬∑lisions), continuem
            else:
                # Estem fora del cluster
                if not outside_cluster:
                    outside_cluster = True
                    reentry_attempts = 0
                
                reentry_attempts += 1
            
            # Movem a la seg√ºent posici√≥
            pos += step_vector
            
            # Si portem massa intents sense tornar a entrar, aturem
            if outside_cluster and reentry_attempts >= max_reentry_attempts:
                break
        
        # Versi√≥ cap enrere - mateixa l√≤gica
        pos = np.array(start_point, dtype=np.float64) - step_vector
        backward_panels = []
        outside_cluster = not self.geometry.contains(Point(pos))
        reentry_attempts = 0
        
        for i in range(300):
            panel = self._create_panel(pos[0], pos[1])
            
            if self.geometry.contains(Point(pos)):
                if self._is_valid_placement(panel, existing_panels + backward_panels + forward_panels):
                    backward_panels.append(panel)
                    if outside_cluster:
                        outside_cluster = False
                    reentry_attempts = 0
            else:
                if not outside_cluster:
                    outside_cluster = True
                    reentry_attempts = 0
                
                reentry_attempts += 1
            
            pos -= step_vector
            
            if outside_cluster and reentry_attempts >= max_reentry_attempts:
                break
        
        # Concatenar resultats (en ordre correcte)
        return backward_panels[::-1] + forward_panels

    def _get_coverage(self, panels):
        """Calcula el porcentaje de √°rea cubierta"""
        if not panels:
            return 0.0
        union = unary_union(panels)
        return union.area / self.geometry.area * 100    #Calcul simple per obtindre el porcentatge cobert

    def optimize_placement(self, num_points=6):
        """Optimiza la colocaci√≥n de paneles, comparando azimuts para tilt <5¬∞"""
        tilt = getattr(self.cluster, 'tilt', 0)
        
        # Configurar separaci√≥n seg√∫n temporada
        if tilt < 5:
            alpha_hivern = 90 - (self.cluster.lat + 23.45)
            self.sep_perp = (self.panel_l * np.sin(np.radians(17.7))) / np.tan(np.radians(alpha_hivern))
        else:
            self.sep_perp = self.sep_row
        
        # Para tejados con baja inclinaci√≥n, comparamos dos escenarios
        if tilt < 5:
            print("[INFO] Tilt <5¬∞ - Comparando escenarios de azimut...")
            
            # ESCENARIO 1: Azimut personalizado (ya calculado por el programa)
            az_personalizado = self.azimuth
            print(f"Escenario 1: Optimizando con azimut personalizado ({az_personalizado}¬∞)")
            
            # Optimizar con azimut personalizado
            best_panels_personalizado = self._optimize_single_scenario(num_points)
            coverage_personalizado = self._get_coverage(best_panels_personalizado)
            
            # ESCENARIO 2: Azimut del tejado (sin la conversi√≥n GIS‚Üímatem√°tica)
            az_tejado = self.cluster.azimuth  # Azimut original del cluster
            print(f"Escenario 2: Optimizando con azimut del tejado ({az_tejado}¬∞)")
            
            # Guardar estado actual
            original_azimuth = self.azimuth
            original_main_dir = self.main_dir.copy()
            original_perp_dir = self.perp_dir.copy()
            original_rotated_panel = self.rotated_panel
            
            # Configurar azimut del tejado (conversi√≥n GIS‚Üímatem√°tica)
            self.azimuth = (90 - az_tejado) % 360
            self.main_dir = np.array([np.cos(np.radians(self.azimuth)), np.sin(np.radians(self.azimuth))])
            self.perp_dir = np.array([-self.main_dir[1], self.main_dir[0]])
            self.rotated_panel = self._rotate_panel(self.base_panel)
            
            # Optimizar con azimut del tejado
            best_panels_tejado = self._optimize_single_scenario(num_points)
            coverage_tejado = self._get_coverage(best_panels_tejado)
            
            # Restaurar estado original
            self.azimuth = original_azimuth
            self.main_dir = original_main_dir
            self.perp_dir = original_perp_dir
            self.rotated_panel = original_rotated_panel
            
            # Comparar resultados
            print(f"\n[COMPARACI√ìN]")
            print(f"Azimut personalizado: {len(best_panels_personalizado)} paneles, {coverage_personalizado:.2f}% cobertura")
            print(f"Azimut del tejado: {len(best_panels_tejado)} paneles, {coverage_tejado:.2f}% cobertura")

            # üìä Calcular multiplicador din√°mico seg√∫n el perfil de sombras
            if hasattr(self.cluster, "points") and len(self.cluster.points) > 0:
                shading_data = np.array([p['shading'] for p in self.cluster.points])
                shading_profile = np.mean(shading_data, axis=0)
                avg_shade = np.mean(shading_profile) / 100.0  # si el CSV va de 0‚Äì100
                multiplier = 1.0 + avg_shade
            else:
                multiplier = 1.2  # fallback por defecto si no hay datos
            print(f"[INFO] Multiplicador din√°mico = {multiplier:.2f}")

            # üìå Decidir con multiplicador din√°mico
            if len(best_panels_tejado) >= len(best_panels_personalizado) * multiplier:
                print(f"[DECISI√ìN] Usando azimut del tejado (‚â•{multiplier:.2f}x m√°s paneles)")
                best_panels = best_panels_tejado
                best_coverage = coverage_tejado
                self.azimuth = (90 - az_tejado) % 360
            else:
                print("[DECISI√ìN] Usando azimut personalizado")
                best_panels = best_panels_personalizado
                best_coverage = coverage_personalizado

            
            # Actualizar direcciones seg√∫n la decisi√≥n final
            self.main_dir = np.array([np.cos(np.radians(self.azimuth)), np.sin(np.radians(self.azimuth))])
            self.perp_dir = np.array([-self.main_dir[1], self.main_dir[0]])
            self.rotated_panel = self._rotate_panel(self.base_panel)
            
        else:
            # Para inclinaciones ‚â•5¬∞, proceder normalmente
            best_panels = self._optimize_single_scenario(num_points)
            best_coverage = self._get_coverage(best_panels)
        
        print(f"\nMejor cobertura final: {best_coverage:.2f}% con {len(best_panels)} paneles")
        return best_panels

    def _optimize_single_scenario(self, num_points):
        """Optimiza la colocaci√≥n para el azimut actualmente configurado"""
        start_lines = self._get_edge_start_points(num_points=num_points)
        best_panels = []
        best_coverage = 0.0
        
        for idx, start_point in enumerate(start_lines):
            panels = []
            added_in_this_pass = True
            attempt = 0
            max_attempts = 10
            
            while attempt < max_attempts and added_in_this_pass:
                added_in_this_pass = False
                main_row = self._place_systematic_row(start_point, panels)
                
                if main_row:
                    panels.extend(main_row)
                    added_in_this_pass = True
                
                # Expansi√≥n perpendicular
                for sign in [1, -1]:
                    current_pos = np.array(start_point) + sign * (self.panel_l + self.sep_perp) * self.perp_dir
                    rows_added = 0
                    global_fail_count = 0
                    max_global_fail_count = 5
                    
                    while rows_added < 20 and global_fail_count < max_global_fail_count:
                        found_row = False
                        
                        for jump in range(0, 15):
                            test_pos = current_pos + sign * jump * (self.panel_l + self.sep_perp) * self.perp_dir
                            new_row = self._place_systematic_row(test_pos, panels)
                            
                            if new_row:
                                panels.extend(new_row)
                                added_in_this_pass = True
                                rows_added += 1
                                current_pos = test_pos
                                global_fail_count = 0
                                found_row = True
                                break
                        
                        if not found_row:
                            global_fail_count += 1
                        
                        current_pos += sign * (self.panel_l + self.sep_perp) * self.perp_dir
                
                if not added_in_this_pass:
                    attempt += 1
            
            coverage = self._get_coverage(panels)
            if coverage > best_coverage:
                best_coverage = coverage
                best_panels = panels
        
        return best_panels

    def visualize(self, panels, show_arrows=True, show_start_points=True):

        fig, ax = plt.subplots(figsize=(12, 12))

        # üî∑ Dibuixar el cluster
        if isinstance(self.geometry, Polygon):
            x, y = self.geometry.exterior.xy
            ax.fill(x, y, alpha=0.3, color='lightblue', label='Cluster')
            ax.plot(x, y, color='blue', linewidth=0.5)
        else:
            for poly in self.geometry.geoms:
                x, y = poly.exterior.xy
                ax.fill(x, y, alpha=0.3, color='lightblue', label='Cluster')
                ax.plot(x, y, color='blue', linewidth=0.5)

        # üü© Dibuixar els panells
        print(f"[INFO] Mostrant {len(panels)} panells col¬∑locats")
        cmap = plt.cm.Greens
        for i, panel in enumerate(panels):
            x, y = panel.exterior.xy
            ax.fill(x, y, color=cmap(0.6), alpha=0.8, edgecolor='black', linewidth=0.3)

            # Opcional: dibuixar fletxa d'orientaci√≥ per alguns panells
            if show_arrows and i % 15 == 0:
                centroid = panel.centroid
                arrow_len = min(self.panel_w, self.panel_l) * 0.6
                ax.arrow(
                    centroid.x, centroid.y,
                    arrow_len * np.cos(np.radians(self.azimuth)),
                    arrow_len * np.sin(np.radians(self.azimuth)),
                    head_width=0.2, head_length=0.2, fc='red', ec='red'
                )

        # ‚ùå Dibuixar els punts d‚Äôinici (debug visual)
        if show_start_points:
            start_points = self._get_edge_start_points()
            if start_points:
                x, y = zip(*start_points)
                ax.scatter(x, y, color='orange', s=50, marker='x', label='Punts inici')

        # üìã Llegenda i t√≠tol
        ax.set_title(f"Optimitzaci√≥ de Panells ‚Äî Cluster {self.cluster.id}\n"
                    f"Azimut: {self.azimuth:.1f}¬∞  |  Tilt: {self.tilt:.1f}¬∞  |  Panells: {len(panels)}",
                    fontsize=14)

        cluster_patch = mpatches.Patch(color='lightblue', label='Cluster')
        panel_patch = mpatches.Patch(color=cmap(0.6), label='Panells solars')
        ax.legend(handles=[cluster_patch, panel_patch])

        # üß≠ Format del gr√†fic
        ax.set_aspect('equal')
        ax.set_xlabel("X")
        ax.set_ylabel("Y")
        ax.grid(True, linestyle='--', alpha=0.3)
        plt.subplots_adjust(left=0.05, right=0.95, top=0.9, bottom=0.05)  # Evita tallar parts del gr√†fic
        plt.show()

    def plot_edge_start_points(self):
        points = self._get_edge_start_points()

        # --- Dibuixar geometria del cluster ---
        fig, ax = plt.subplots(figsize=(6,6))
        if self.geometry.geom_type == "Polygon":
            x, y = self.geometry.exterior.xy
            ax.plot(x, y, color="black")
            for interior in self.geometry.interiors:
                xi, yi = interior.xy
                ax.plot(xi, yi, color="red", linestyle="--")
        elif self.geometry.geom_type == "MultiPolygon":
            for poly in self.geometry.geoms:
                x, y = poly.exterior.xy
                ax.plot(x, y, color="black")
                for interior in poly.interiors:
                    xi, yi = interior.xy
                    ax.plot(xi, yi, color="red", linestyle="--")

        # --- Dibuixar punts d'inici ---
        px = [p[0] for p in points]
        py = [p[1] for p in points]
        ax.scatter(px, py, color="blue", s=40, label="Start points")

        ax.set_aspect("equal", "box")
        ax.legend()
        plt.show()


class PanelPointAssociator:
    """ Aquest programa l'entenc com un preparador del seguent, es podria dir que es com un clster2.0 per altre tipus d'informaci√≥
        Genera els calculs per interconectar les plaques colocades i els punts del perfil de sombras
        Que fa:
            -Classifica el spunts en funci√≥ de si estan dintre, al borde o aprop de la placa amb un sistema de pesos
            -Despres associa els pessos a uns punts per un panel_id concret
            -Retorna els punts per un panel_id concret

    """
    def __init__(self, cluster, solar_panels, border_distance=0.5, near_distance=1.0,
                 inner_weight=1.0, border_weight=0.8, near_weight=0.3):
        self.cluster = cluster
        self.solar_panels = solar_panels
        self.border_distance = border_distance
        self.near_distance = near_distance
        self.inner_weight = inner_weight
        self.border_weight = border_weight
        self.near_weight = near_weight

        self.points = np.array([[p['x'], p['y']] for p in cluster.points])
        self.kdtree = KDTree(self.points)

        # Llista: un DataFrame per cada panell amb tots els punts associats
        self.panel_point_details = []

        self._associate_and_weight()

    def _classify_and_weight(self, point, panel):
        p = Point(point)
        if panel.contains(p):
            return "inside", self.inner_weight
        if panel.buffer(self.border_distance).contains(p):
            dist = p.distance(panel.boundary)
            w = self.inner_weight - (self.inner_weight - self.border_weight) * (dist / self.border_distance)
            return "border", max(self.border_weight, w)
        if panel.buffer(self.near_distance).contains(p):
            dist = p.distance(panel.buffer(self.border_distance).boundary)
            max_dist = self.near_distance - self.border_distance
            w = self.border_weight - (self.border_weight - self.near_weight) * (dist / max_dist)
            return "near", max(self.near_weight, w)
        return None, 0.0

    def _associate_and_weight(self):
        for panel_id, panel in enumerate(self.solar_panels):
            center = [panel.centroid.x, panel.centroid.y]
            radius = max(panel.bounds[2] - panel.bounds[0],
                         panel.bounds[3] - panel.bounds[1]) / 2 + self.near_distance
            nearby_idxs = self.kdtree.query_ball_point(center, radius)

            records = []
            for idx in nearby_idxs:
                point = self.points[idx]
                category, weight = self._classify_and_weight(point, panel)
                if category:
                    p = self.cluster.points[idx]
                    records.append({
                        'panel_id': panel_id,
                        'point_id': idx,
                        'x': p['x'],
                        'y': p['y'],
                        'z': p['z'],
                        'category': category,
                        'weight': weight,
                        'shading': p.get('shading', None)
                    })
            df = pd.DataFrame(records)
            self.panel_point_details.append(df)

    def get_panel_points(self, panel_id):
        """
        Retorna el DataFrame amb tots els punts associats al panell indicat.
        """
        if 0 <= panel_id < len(self.panel_point_details):
            return self.panel_point_details[panel_id]
        else:
            raise IndexError(f"Panel_id {panel_id} fora de rang.")


class TiltOptimizer:
    def __init__(self, cluster, panel_point_details):
        """
        Inicializa el optimizador.
        """
        self.cluster = cluster
        self.panel_point_details = panel_point_details
        

    def compute_optimal_orientation(self):
      
        tilt = getattr(self.cluster, 'tilt', 0)
        if tilt < 5:   #tilt menor a 5
            print("[INFO] Tilt < 45. Calcular media independiente por panel.")
            return self.calculo_total_flat()
        else:
            print(f"[INFO] Tilt = {tilt}. Calcular media global para toda la cubierta.")
            resultados = {panel_id: tilt for panel_id in range(len(self.panel_point_details))}
            resultados["media_valida"] = tilt
            return resultados


    def _comprovar_invierno(self, punto: dict) -> bool:
        """
        Versi√≥n mejorada con verificaci√≥n de datos y logging
        """
        # 1. Verificar que tenemos datos de sombra
        if 'shading' not in punto or len(punto['shading']) != 360:
            print("[ERROR] Punto no tiene perfil de sombra v√°lido")
            return False
        
        azimut = int(round(self.cluster.azimuth)) % 360
        shading_profile = np.array(punto['shading'])
        
        # 2. Definir ventana m√°s amplia para mayor robustez
        ventana_size = 15  # ¬±15 grados
        ventana = [(azimut + i) % 360 for i in range(-ventana_size, ventana_size + 1)]
        
        # 3. Calcular elevaci√≥n solar en invierno (m√°s preciso)
        def get_solar_elevations(date):
            times = pd.date_range(f"{date} 06:00", f"{date} 18:00", freq='10min', tz=cluster.time_zone)
            solpos = solarposition.get_solarposition(times, self.cluster.lat, self.cluster.lon)
            # Para cada √°ngulo en la ventana, encontrar la elevaci√≥n m√°xima
            elevaciones = []
            for angle in ventana:
                idx = (solpos['azimuth'] - angle).abs().idxmin()
                elevaciones.append(solpos.loc[idx, 'elevation'])
            return np.max(elevaciones)
        
        elev_invierno = get_solar_elevations("2024-12-21")
        #print(f"[DEBUG] Elevaci√≥n m√°xima en invierno: {elev_invierno:.1f}¬∞")
        
        # 4. Analizar sombras en la ventana
        sombras = shading_profile[ventana]
        sombra_count = np.sum(sombras > elev_invierno)
        total_puntos = len(ventana)
       
        # 5. Decisi√≥n basada en mayor√≠a despejada (60%)
        return sombra_count <= total_puntos * 0.6
    
    def _compute_roof_single(self, df, panel_id):
        
        azimut = int(round(self.cluster.azimuth)) % 360
        algun_falso = False

        for _, punto_row in df.iterrows():
            punto = {
                'shading': punto_row['shading']
            }

            if not self._comprovar_invierno(punto):
                algun_falso = True

        if algun_falso:
            # Verano (ajustable: f√≥rmula para verano)
            lat = self.cluster.lat
            tilt = max(lat * 0.93 - 21, 0)  # aqui haremos cambios
            
        else:
            # Fijo para todo el a√±o
            lat = self.cluster.lat
            if lat < 25:
                tilt = lat * 0.87
            elif 25 <= lat <= 50:
                tilt = lat * 0.76 + 3.1
            else:
                tilt = lat  # para >50, aproximado
            

        
        df_inside_border = df[df['category'].isin(['inside', 'border'])]
        if df_inside_border.empty:
            return "NO √öTIL"
        
                        # Definimos una ventana de ¬±5 grados para el azimut
        delta = 5
        ventana = [(azimut + i) % 360 for i in range(-delta, delta + 1)]

        sombras_inside_border = []

        for _, row in df_inside_border.iterrows():
            shading_profile = list(row['shading'])
            sombras_en_ventana = [shading_profile[a] for a in ventana]
            sombra_media = np.mean(sombras_en_ventana)
            sombras_inside_border.append(sombra_media)

        sombra_maxima = max(sombras_inside_border)

        

        if sombra_maxima > 50:
            print(f"[DESCARTADO] Panel {panel_id}: sombra m√°xima > 45¬∞, NO √öTIL.")
            return "NO √öTIL"
        else:
            print(f"[RESULTADO] Panel {panel_id}: tilt recomendado final: {tilt:.1f}¬∞")
            return tilt

    def calculo_total_flat(self):
       
        resultados = {}
        tilts_validos = []

        for panel_id, df in enumerate(self.panel_point_details):
            if df.empty:
                continue

            flat_resultado = self._compute_roof_single(df, panel_id)

            resultados[panel_id] = flat_resultado

            if isinstance(flat_resultado, (int, float)):
                tilts_validos.append(flat_resultado)

        if tilts_validos:
            media = np.mean(tilts_validos)
            print(f"\n‚úÖ Tilt medio recomendado para placas v√°lidas: {media:.1f}¬∞")
            resultados["media_valida"] = media
        else:
            print("\n‚ö†Ô∏è Ninguna placa result√≥ √∫til.")
            resultados["media_valida"] = None

        return resultados


def plot_tilt_results(cluster_geometry, solar_panels, tilt_results):
 
    fig, ax = plt.subplots(figsize=(10, 10))
    ax.set_aspect('equal')
    plt.title("Paneles y su inclinaci√≥n recomendada")

    # üìê Dibuja la geometr√≠a del cluster al fondo
    if isinstance(cluster_geometry, Polygon):
        x, y = cluster_geometry.exterior.xy
        ax.fill(x, y, alpha=0.3, color='lightblue', label='Cluster')
    else:  # MultiPolygon
        for poly in cluster_geometry.geoms:
            x, y = poly.exterior.xy
            ax.fill(x, y, alpha=0.3, color='lightblue', label='Cluster')

    # üìê Dibuja los paneles uno a uno
    for panel_id, panel_geom in enumerate(solar_panels):
        result = tilt_results.get(panel_id, "NO √öTIL")
        if result == "NO √öTIL":
            color = "red"
            label = "No √∫til"
        elif isinstance(result, (int, float)):
            if result > 45:
                color = "red"
                label = "No √∫til"
            else:
                color = "green"
                label = f"{result:.1f}¬∞"
        else:
            color = "gray"
            label = "Desconocido"

        if isinstance(panel_geom, Polygon):
            x, y = panel_geom.exterior.xy
            ax.fill(x, y, alpha=0.6, color=color)
            centroid = panel_geom.centroid
            ax.text(centroid.x, centroid.y, label,
                    ha='center', va='center', fontsize=7)

    plt.xlabel("X")
    plt.ylabel("Y")
    plt.grid(True, linestyle='--', alpha=0.3)
    plt.legend(loc='upper right')
    plt.show()





    # Ejemplo de uso integrado


class PVlibSimulator:
    def __init__(self, cluster, tilt_dict, panel_point_details,
                 test_mode=False, n_test_hours=120,
                 module_name='LG_Electronics_Inc__LG405N2W_A5',
                 inverter_name='SunPower__SPR_4000m__240V_',
                 temp_model='close_mount_glass_glass'):

        self.cluster = cluster
        self.tilt_dict = tilt_dict
        self.panel_point_details = panel_point_details
        self.test_mode = test_mode
        self.n_test_hours = n_test_hours
        self.debug = True

        # üìç Ubicaci√≥n con TZ correcta
        self.location = location.Location(
            latitude=cluster.lat,
            longitude=cluster.lon,
            tz= cluster.time_zone,
            altitude=getattr(cluster, "altitude", 100)
        )

        # üå§ Cargar datos meteorol√≥gicos reales desde PVGIS
        print("[INFO] Descargando TMY de PVGIS...")
        self.weather, *_ = iotools.get_pvgis_tmy(cluster.lat, cluster.lon)

        # Asegurar zona horaria
        if self.weather.index.tz is None:
            self.weather = self.weather.tz_localize('UTC').tz_convert(self.location.tz)
        else:
            self.weather = self.weather.tz_convert(self.location.tz)

        # Recorte para modo test
        if self.test_mode:
            self.weather = self.weather.head(self.n_test_hours)

        # ‚öôÔ∏è Componentes del sistema
        cec_modules = pvsystem.retrieve_sam('CECMod')           # ‚úÖ no SandiaMod
        cec_inverters = pvsystem.retrieve_sam('CECInverter')    # ‚úÖ dataset correcto

        self.module = cec_modules['Sunpower_SPR_X20_450_COM']                  # usa el nombre que ya tienes
        self.inverter = cec_inverters['SunPower__SPR_4000m__240V_']
        self.temp_params = TEMPERATURE_MODEL_PARAMETERS['sapm'][temp_model]
  
    def _col_name(self, df, names):
        for n in names:
            if n in df.columns:
                return n
        return None

    def simulate_panel_optimized(self, panel_id, time_resolution=None, return_modelchain=False):
        if time_resolution is None:
            time_resolution = f'{self.cluster.simulation_time}min' 
        tilt = self.tilt_dict.get(panel_id)
        if tilt == "NO √öTIL" or not isinstance(tilt, (int, float)):
            return None

        # üìå Seleccionar punto representativo para este panel
        panel_points_df = self.panel_point_details[panel_id]
        if not panel_points_df.empty:
            for category in ['inside', 'border', 'near']:
                rep_point = panel_points_df[panel_points_df['category'] == category]
                if not rep_point.empty:
                    punto = rep_point.loc[rep_point['weight'].idxmax()].to_dict()
                    break
            else:
                print(f"[WARN] Panel {panel_id} no tiene puntos v√°lidos")
                return None
        else:
            print(f"[ERROR] No hay datos de puntos para el panel {panel_id}")
            return None
        print(f"[DEBUG] Panel {panel_id}: usando punto {punto.get('point_id')} con sombra hash {hash(tuple(punto['shading']))}")



        # üåì Perfil de sombras
        shading_profile = np.array(punto['shading'], dtype=float)
        if shading_profile.size != 360:
            shading_profile = np.pad(shading_profile, (0, 360 - shading_profile.size), 'constant')[:360]

        print(f"Panel {panel_id} usando punto {punto.get('point_id', 'N/A')} "
            f"(Cat: {punto['category']}, Peso: {punto['weight']:.2f})")

        # ‚è± Preparar datos meteorol√≥gicos reales
        if time_resolution != '1min':
            weather_data = self.weather.resample(time_resolution).interpolate(method='time').asfreq(time_resolution)
        else:
            weather_data = self.weather.copy()

        # üìã Nombres de columnas
        col_ghi = self._col_name(weather_data, ['ghi', 'G(h)', 'GHI']) or 'ghi'
        col_dni = self._col_name(weather_data, ['dni', 'Gb(n)', 'DNI']) or 'dni'
        col_dhi = self._col_name(weather_data, ['dhi', 'Gd(h)', 'DHI']) or 'dhi'
        col_temp = self._col_name(weather_data, ['temp_air', 'temp', 'air_temperature', 'TA']) or 'temp_air'
        col_wind = self._col_name(weather_data, ['wind_speed', 'wind', 'WS']) or 'wind_speed'

        for col, default in [(col_ghi, 0.0), (col_dni, 0.0), (col_dhi, 0.0),
                            (col_temp, 20.0), (col_wind, 1.0)]:
            if col not in weather_data:
                weather_data[col] = default

        def svf_from_shading_profile(shading_profile_deg):
            """Calcula SVF (sky view factor) a partir d'un perfil d'horitz√≥ de 360 valors (graus)."""
            h = np.radians(np.asarray(shading_profile, dtype=float))
            return float(np.clip(np.mean(np.cos(h)**2), 0.0, 1.0))




        # üåû Calcular posiciones solares
        solpos = pvlib.solarposition.get_solarposition(
            time=weather_data.index,
            latitude=self.cluster.lat,
            longitude=self.cluster.lon
        )

        # calcula SVF una sola vegada
        SVF = svf_from_shading_profile(shading_profile)

        if int(time_resolution.replace('min','')) <= 10:
            # --- Caso resoluciones finas (‚â§10min): exacto por instante ---
           
            solar_elevation = solpos['elevation'].values
            solar_azimuth = np.mod(np.round(solpos['azimuth']).astype(int), 360)
            shading_angles = shading_profile[solar_azimuth]
            unshaded = solar_elevation > shading_angles
            shaded_mask = ~unshaded

            weather_mod = weather_data.copy()
            weather_mod[col_dni] = np.where(shaded_mask, 0.0, weather_mod[col_dni])

            # separaci√≥ difusa en circumsolar i isotropa
            ai = (weather_data[col_dni] / (weather_data[col_dni] + 3.0 * weather_data[col_dhi])).clip(0, 1)
            dhi_circ = ai * weather_data[col_dhi]
            dhi_iso  = (1 - ai) * weather_data[col_dhi]

            # aplica ombres
            dhi_circ_adj = np.where(shaded_mask, 0.0, dhi_circ)              # circumsolar bloquejat si hi ha obstacle
            dhi_iso_adj  = np.where(shaded_mask, dhi_iso * SVF, dhi_iso)     # isotropa redu√Øda pel SVF

            weather_mod[col_dhi] = dhi_circ_adj + dhi_iso_adj
          
            # recalcula GHI
            cos_theta_z = np.cos(np.radians(solpos['zenith']))
            ghi_new = weather_mod[col_dhi] + weather_mod[col_dni] * np.maximum(cos_theta_z, 0)
            weather_mod[col_ghi] = ghi_new

        else:
            # --- Caso resoluciones >10min: fracci√≥n de sombra por bloque ---
            elev_blk = solpos['elevation'].resample(time_resolution)
            azim_blk = solpos['azimuth'].resample(time_resolution)

            def shaded_fraction_from_block(block_elev, block_azim, shading_profile_deg):
                if block_elev.empty:
                    return 0.0
                az = np.mod(np.round(block_azim.values).astype(int), 360)
                el = block_elev.values
                counts = np.bincount(az, minlength=360).astype(float)
                total = counts.sum()
                if total == 0:
                    return 0.0
                sum_elev = np.bincount(az, weights=el, minlength=360)
                mean_elev = np.divide(sum_elev, counts, out=np.zeros_like(sum_elev), where=counts > 0)
                shaded_by_bin = (mean_elev <= shading_profile_deg)
                frac = (counts * shaded_by_bin).sum() / total
                return float(frac)

            shading_profile_arr = np.asarray(shading_profile, dtype=float)

            shaded_fraction = []
            for (t_start, elev_series), (_, azim_series) in zip(elev_blk, azim_blk):
                frac = shaded_fraction_from_block(elev_series, azim_series, shading_profile_arr)
                shaded_fraction.append((t_start, frac))

            shaded_fraction = pd.Series(
                data=[v for _, v in shaded_fraction],
                index=[i for i, _ in shaded_fraction]
            )

            weather_blk = weather_data.resample(time_resolution).mean()

            # DNI ‚Üí redu√Øt per la fracci√≥ d‚Äôombra
            dni_blk = weather_blk[col_dni] * (1.0 - shaded_fraction)

            # separaci√≥ difusa en circumsolar i isotropa
            ai_blk = (weather_blk[col_dni] / (weather_blk[col_dni] + 3.0 * weather_blk[col_dhi])).clip(0, 1)
            dhi_circ_blk = ai_blk * weather_blk[col_dhi]
            dhi_iso_blk  = (1 - ai_blk) * weather_blk[col_dhi]

            # aplica ombres
            dhi_circ_adj_blk = dhi_circ_blk * (1.0 - shaded_fraction)   # circumsolar atenuat com DNI
            dhi_iso_adj_blk  = dhi_iso_blk * ((1.0 - shaded_fraction) + shaded_fraction * SVF)

            dhi_blk = dhi_circ_adj_blk + dhi_iso_adj_blk

            # recalcula GHI per bloc
            zenith_blk = solpos['zenith'].resample(time_resolution).mean()
            cos_theta_z_blk = np.cos(np.radians(zenith_blk))
            ghi_blk = dhi_blk + dni_blk * np.maximum(cos_theta_z_blk, 0)

            weather_mod = weather_blk.copy()
            weather_mod[col_dni] = dni_blk
            weather_mod[col_dhi] = dhi_blk
            weather_mod[col_ghi] = ghi_blk

        # üìä Totals mensuales
        monthly = weather_mod[[col_dni, col_ghi, col_dhi]].resample('ME').sum()



        # üîå Crear sistema PV
        system = PVSystem(
            surface_tilt=tilt,
            surface_azimuth=self.cluster.azimuth,
            module_parameters=self.module,
            inverter_parameters=self.inverter,
            temperature_model_parameters=self.temp_params
        )
     

        mc = ModelChain(
            system,
            self.location,
            aoi_model='physical',
            spectral_model='no_loss',
            temperature_model='sapm'
        )

       
        try:
            #revisio
            weather_for_mc = pd.DataFrame(index=weather_mod.index)
            weather_for_mc['dni']        = weather_mod[col_dni].astype(float)
            weather_for_mc['ghi']        = weather_mod[col_ghi].astype(float)
            weather_for_mc['dhi']        = weather_mod[col_dhi].astype(float)
            weather_for_mc['temp_air']   = weather_mod[col_temp].astype(float)
            weather_for_mc['wind_speed'] = weather_mod[col_wind].astype(float)

            # Opcional: garantiza no-negativos
            for c in ['dni','ghi','dhi']:
                weather_for_mc[c] = weather_for_mc[c].clip(lower=0)
        
            mc.run_model(weather_mod)
            ac = mc.results.ac  # W

            poa_global = mc.results.total_irrad['poa_global']  # W/m¬≤
            ac = ac.clip(lower=0.0)
            if len(ac) < 2:
                dt_h = 1.0
            else:
                dt_h = (ac.index[1] - ac.index[0]).total_seconds() / 3600.0

            panel_area_m2 = 1.7  # set your real panel area here

            # --- energy per timestep (kWh) for the panel (total kWh per panel) ---
            energy_step_kwh = ac * dt_h / 1000.0           # Series indexed like ac, units kWh (per step) for the whole panel
            energy_monthly_kwh = energy_step_kwh.groupby(energy_step_kwh.index.month).sum().reindex(range(1,13), fill_value=0.0)
            energy_monthly_kwh_m2 = energy_monthly_kwh / panel_area_m2


            # --- POA: energy per timestep (kWh/m¬≤) ---
            poa_step_kwh_m2 = poa_global * dt_h / 1000.0
            poa_monthly_kwh_m2 = poa_step_kwh_m2.groupby(poa_step_kwh_m2.index.month).sum().reindex(range(1,13), fill_value=0.0)
            
            # Build monthly dicts for CSV
            monthly_panel_dict = {f"energy_kwh_month_{str(m).zfill(2)}": round(v, 3)
                                for m, v in enumerate(energy_monthly_kwh.values, start=1)}
            monthly_panel_m2_dict = {f"energy_kwh_m2_month_{str(m).zfill(2)}": round(v, 3)
                                    for m, v in enumerate(energy_monthly_kwh_m2.values, start=1)}
            monthly_poa_dict = {f"poa_kwh_m2_month_{str(m).zfill(2)}": round(v, 3)
                                for m, v in enumerate(poa_monthly_kwh_m2.values, start=1)}

            # Totals
            total_energy_kwh = energy_monthly_kwh.sum()
            total_energy_kwh_m2 = energy_monthly_kwh_m2.sum()




            #Per plot final
            if not hasattr(self, 'panel_energy_results'):
                self.panel_energy_results = {}
            
            # Store just the essential yearly energy data
            self.panel_energy_results[panel_id] = {
                'yearly_energy_kwh': float(total_energy_kwh),
                'yearly_energy_kwh_m2': float(total_energy_kwh_m2),
                'tilt': tilt,
                'point_id': punto.get('point_id')
            }

            # Store key results as instance attributes for later access
            self.ac = ac
            self.poa_global = poa_global
            self.dt_h = dt_h
            self.panel_area_m2 = panel_area_m2
            self.energy_monthly_kwh = energy_monthly_kwh
            self.energy_monthly_kwh_m2 = energy_monthly_kwh_m2
            self.poa_monthly_kwh_m2 = poa_monthly_kwh_m2
            self.panel_id = panel_id
            self.col_ghi = col_ghi
            self.col_dni = col_dni
            self.col_dhi = col_dhi
            self.monthly = monthly
            self.monthly_panel_dict = monthly_panel_dict
            

            # Compose result dict (example)
            result = {
                "panel_id": panel_id,
                "tilt_deg": tilt,
                "max_power_w": float(ac.max()),
                "mean_power_w": float(ac.mean()),
                "total_energy_kwh": float(total_energy_kwh),
                #"total_energy_kwh_m2": float(total_energy_kwh_m2),
                "point_id": punto.get('point_id'),
                "point_category": punto['category'],
                #"point_weight": float(punto['weight']),
                **monthly_panel_dict,
                #**monthly_panel_m2_dict,
                **monthly_poa_dict
            }
            return (mc, result) if return_modelchain else result

        except Exception as e:
            print(f"[ERROR] simulando panel {panel_id}: {str(e)}")
            return None

    def compute_and_save_csv(self, filename="results.csv", workers=4):
        from concurrent.futures import ThreadPoolExecutor

        # Selecci√≥n de paneles con tilt v√°lido
        panel_ids = [i for i in range(len(self.panel_point_details))
                    if isinstance(self.tilt_dict.get(i), (int, float))]

        results = []

        # Ejecuci√≥n paralela segura con ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=workers) as executor:
            futures = {executor.submit(self.simulate_panel_optimized, pid): pid for pid in panel_ids}
            for fut in futures:
                res = fut.result()
                if res:
                    results.append(res)

        if results:
            df = pd.DataFrame(results).sort_values("panel_id")
            df.to_csv(filename, index=False)
            print(f"‚úÖ Saved results to {filename}")
            print(df.describe())
            return df
        else:
            print("‚ö†Ô∏è No valid results to save")
            return None
    
    def plot_panel_power_and_horizon(self, panel_id, fecha='2024-06-21', window_minutes=5):
        """
        Muestra:
        1) Potencia generada vs. periodos de sombra en el d√≠a indicado
        2) Perfil de sombras + trayectoria solar del mismo d√≠a
        """
        import matplotlib.pyplot as plt
        from matplotlib.patches import Patch
        import numpy as np
        import pandas as pd
        import ast

        try:
            # 1) Simular el panel para obtener mc y punto representativo
            sim_res = self.simulate_panel_optimized(panel_id, return_modelchain=True)
            if not sim_res:
                print(f"[ERROR] No se pudo simular el panel {panel_id}")
                return
            mc, summary = sim_res

            panel_df = self.panel_point_details[panel_id]

            # Buscar punto representativo del resultado
            if 'point_id' in summary:
                mask = panel_df['point_id'] == summary['point_id']
                if mask.any():
                    punto = panel_df[mask].iloc[0]
                else:
                    punto = panel_df.iloc[0]
            else:
                for cat in ['inside', 'border', 'near']:
                    subset = panel_df[panel_df['category'] == cat]
                    if not subset.empty:
                        punto = subset.iloc[0]
                        break

            # 2) Obtener perfil de sombras
            shading_raw = punto['shading']
            if isinstance(shading_raw, str):
                try:
                    shading_profile = np.array(ast.literal_eval(shading_raw), dtype=float)
                except Exception:
                    shading_profile = np.array([float(x) for x in shading_raw.split(',') if x.strip()], dtype=float)
            else:
                shading_profile = np.array(shading_raw, dtype=float)

            if shading_profile.size < 360:
                shading_profile = np.pad(shading_profile, (0, 360 - shading_profile.size), 'constant', constant_values=0)
            elif shading_profile.size > 360:
                shading_profile = shading_profile[:360]

            # 3) Datos de potencia para el d√≠a
            ac = mc.results.ac
            target_date = pd.to_datetime(fecha).date()
            mask_day = ac.index.date == target_date
            day_power = ac[mask_day]
            if day_power.empty:
                print(f"[WARN] No hay datos para la fecha {fecha}")
                return

            solpos_day = pvlib.solarposition.get_solarposition(day_power.index, self.cluster.lat, self.cluster.lon)
            azs = np.mod(np.round(solpos_day['azimuth']).astype(int), 360)
            elevs = solpos_day['elevation'].values

            # 4) Trayectoria solar para gr√°fico inferior
            times_day = pd.date_range(fecha + ' 06:00', fecha + ' 21:00', freq='10min', tz=self.location.tz)
            solpos_traj = pvlib.solarposition.get_solarposition(times_day, self.cluster.lat, self.cluster.lon)
            az_traj = np.mod(np.round(solpos_traj['azimuth']).astype(int), 360)
            el_traj = solpos_traj['elevation'].values

            # 5) Graficar
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 9), gridspec_kw={'height_ratios': [2, 1]})

            # --- Arriba: Potencia y sombra ---
            ax1.plot(day_power.index, day_power.values, color='green', lw=2, label='Potencia generada')
            for t, az, el in zip(day_power.index, azs, elevs):
                if el > 0 and el <= shading_profile[az]:
                    ax1.axvspan(t - pd.Timedelta(minutes=window_minutes),
                                t + pd.Timedelta(minutes=window_minutes),
                                color='red', alpha=0.3)
            ax1.set_ylabel('Potencia AC (W)')
            ax1.set_title(f'Panel {panel_id} ‚Äî Potencia y periodos sombreados ({fecha})')
            ax1.grid(True, alpha=0.3)
            ax1.legend(handles=[
                Patch(facecolor='green', label='Potencia generada'),
                Patch(facecolor='red', alpha=0.3, label='Sombra')
            ])

            # --- Abajo: Horizonte y trayectoria ---
            angulos = np.arange(0, 360)
            ax2.plot(angulos, shading_profile, color='darkred', lw=2, label='Perfil de sombras')
            ax2.plot(az_traj, el_traj, color='gold', label='Sol del d√≠a')
            ax2.set_xlim(0, 360)
            ax2.set_ylim(0, 90)
            ax2.set_xticks(np.arange(0, 361, 45))
            ax2.set_xticklabels(['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N'])
            ax2.set_xlabel('Azimut (¬∞)')
            ax2.set_ylabel('Elevaci√≥n (¬∞)')
            ax2.grid(True, alpha=0.3)
            ax2.legend()

            plt.tight_layout()
            plt.show()

        except Exception as e:
            print(f"[ERROR] plot_panel_power_and_horizon: {e}")

    def info_important(self):
        # Verificar que se hayan calculado resultados
        required_attrs = ['ac', 'poa_global', 'dt_h', 'panel_area_m2',
                        'energy_monthly_kwh', 'energy_monthly_kwh_m2', 
                        'poa_monthly_kwh_m2', 'monthly', 'col_ghi', 'col_dhi', 'col_dni']
        
        missing = [attr for attr in required_attrs if not hasattr(self, attr)]
        if missing:
            print(f"[WARN] No se han simulado paneles todav√≠a. Faltan atributos: {missing}")
            return

        # Calcular energ√≠as
        poa_energy_kwh_m2 = self.poa_global.sum() * self.dt_h / 1000.0
        ac_energy_kwh_m2 = self.ac.sum() * self.dt_h / 1000.0 / self.panel_area_m2

        efficiency_estimate = ac_energy_kwh_m2 / poa_energy_kwh_m2 if poa_energy_kwh_m2 > 0 else 0

        print(f"Estimated system efficiency: {efficiency_estimate * 100:.2f}%")
        print(f"Average monthly panel energy (kWh): {self.energy_monthly_kwh.values.mean():.2f}")
        print(f"Average monthly AC energy per m¬≤ (kWh/m¬≤): {self.energy_monthly_kwh_m2.values.mean():.2f}")
        print(f"Average monthly POA irradiance energy (kWh/m¬≤): {self.poa_monthly_kwh_m2.values.mean():.2f}")
        print(f"Ghi energy (kWh/m¬≤): {self.monthly[self.col_ghi].sum() * self.dt_h / 1000.0:.2f}")
        print(f"Dhi energy (kWh/m¬≤): {self.monthly[self.col_dhi].sum() * self.dt_h / 1000.0:.2f}")
        print(f"Dni energy (kWh/m¬≤): {self.monthly[self.col_dni].sum() * self.dt_h / 1000.0:.2f}")


    def _get_poa_samples(self, cluster=None, solpos=None, max_points=None):
        """
        Optimized version that works with any cluster
        """
        from scipy.spatial import cKDTree
        target_cluster = cluster if cluster else self.cluster
        all_points = target_cluster.points
        
        # Efficient sampling if many points
        if max_points and len(all_points) > max_points:
            coords = np.array([[p['x'], p['y']] for p in all_points])
            tree = cKDTree(coords)
            
            if max_points <= 1000:
                indices = np.random.choice(len(coords), max_points, replace=False)
            else:
                _, indices = tree.query(tree.data, k=1, workers=-1)
                indices = np.unique(indices)[:max_points]
            
            sample_points = [all_points[i] for i in indices]
        else:
            sample_points = all_points

        # Calculate solar position if not provided
        if solpos is None:
            solpos = pvlib.solarposition.get_solarposition(
                time=self.weather.index,
                latitude=target_cluster.lat,
                longitude=target_cluster.lon
            )

        # Process points
        points = np.zeros((len(sample_points), 2))
        values = np.zeros(len(sample_points))
        valid_count = 0
        
        for i, point in enumerate(sample_points):
            try:
                shading = np.array(point['shading'], dtype=np.float32)
                if shading.size != 360:
                    shading = np.interp(np.linspace(0, 359, 360),
                                     np.arange(shading.size),
                                     shading)
                
                poa = self.calcular_poa_punt(
                    x=point['x'],
                    y=point['y'],
                    shading_profile=shading,
                    solpos=solpos,
                    cluster=target_cluster
                )
                
                if poa is not None:
                    points[valid_count] = [point['x'], point['y']]
                    values[valid_count] = poa
                    valid_count += 1
                    
            except Exception as e:
                print(f"Error in point {i}: {str(e)[:50]}...")
                continue

        return points[:valid_count], values[:valid_count]

    def find_csv_for_cluster(self, building_path, cluster_id):
        """Find CSV with proper path handling"""
        # Go up one level from Plane Identification to building folder
        building_root = os.path.dirname(os.path.dirname(building_path))
        csv_dir = os.path.join(building_root, "Shading")
        expected_csv = f"{cluster_id}.csv"
        csv_path = os.path.normpath(os.path.join(csv_dir, expected_csv))

        if os.path.exists(csv_path):
            return csv_path
        
        # Try alternative names
        for alt_name in [f"cluster_{cluster_id}.csv", f"Cluster{cluster_id}.csv"]:
            alt_path = os.path.join(csv_dir, alt_name)
            if os.path.exists(alt_path):
                return alt_path
                
        raise FileNotFoundError(f"No CSV found for cluster {cluster_id} in {csv_dir}")

    def calcular_poa_punt(self, x, y, shading_profile, solpos=None, cluster=None):
        target_cluster = cluster if cluster else self.cluster

        try:
            if solpos is None:
                solpos = pvlib.solarposition.get_solarposition(
                    time=self.weather.index,
                    latitude=target_cluster.lat,
                    longitude=target_cluster.lon
                )

            solar_az = np.clip(np.mod(np.round(solpos['azimuth']).astype(int), 360), 0, 359)
            shaded = solpos['elevation'] <= shading_profile[solar_az]

            # Copiar datos meteorol√≥gicos
            weather_mod = self.weather.copy()

            # Aplicar sombra
            weather_mod['dni'] = np.where(shaded, 0.0, weather_mod['dni'])

            # Opci√≥n conservadora: quitar un % de difusa en sombra total
            diff_factor = 0.6  # 50% de difusa en sombra
            weather_mod['dhi'] = np.where(shaded, weather_mod['dhi'] * diff_factor, weather_mod['dhi'])

            # Recalcular GHI con datos filtrados
            cos_zenith = np.cos(np.radians(solpos['zenith']))
            weather_mod['ghi'] = weather_mod['dhi'] + weather_mod['dni'] * np.maximum(cos_zenith, 0)

            # Calcular POA
            poa = pvlib.irradiance.get_total_irradiance(
                surface_tilt=target_cluster.tilt,
                surface_azimuth=target_cluster.azimuth,
                solar_zenith=solpos['apparent_zenith'],
                solar_azimuth=solpos['azimuth'],
                dni=weather_mod['dni'],
                ghi=weather_mod['ghi'],
                dhi=weather_mod['dhi'],
                albedo=0.2
            )['poa_global']

            # Integraci√≥n a kWh/m¬≤
            dt_h = (self.weather.index[1] - self.weather.index[0]).total_seconds() / 3600
            return poa.sum() * dt_h / 1000

        except Exception as e:
            print(f"Error calculating POA at ({x}, {y}): {e}")
            return None
    
    def _plot_single_heatmap(self, ax, cluster, points, values):
        """Plot a single heatmap on given axis"""
        x_min, y_min, x_max, y_max = cluster.geometry.bounds
        xi, yi = np.meshgrid(
            np.linspace(x_min, x_max, 200),
            np.linspace(y_min, y_max, 200)
        )
        rbf = Rbf(points[:,0], points[:,1], values, function='thin_plate')
        zi = rbf(xi, yi)
        
        mask = np.array([[not cluster.geometry.contains(Point(x, y)) 
                        for x, y in zip(xi.ravel(), yi.ravel())]]).reshape(xi.shape)
        zi[mask] = np.nan

        cmap = LinearSegmentedColormap.from_list('thermal', ['#1a2c8b', '#ffffff', '#a51700'])
        contour = ax.contourf(xi, yi, zi, levels=20, cmap=cmap, alpha=0.9)
        plt.colorbar(contour, ax=ax, label='POA Anual (kWh/m¬≤)')

        if isinstance(cluster.geometry, Polygon):
            x, y = cluster.geometry.exterior.xy
            ax.plot(x, y, 'k-', linewidth=0.5)
        else:
            for poly in cluster.geometry.geoms:
                x, y = poly.exterior.xy
                ax.plot(x, y, 'k-', linewidth=0.5)
   
    def plot_total_POA(self):
        """Visualize all clusters together in one plot with consistent color scale"""
        try:
            gdf = gpd.read_file(self.cluster.gpkg_path)
            cluster_ids = gdf['cluster'].unique() if 'cluster' in gdf.columns else [1]
            
            # Create single figure
            fig, ax = plt.subplots(figsize=(14, 10))
            
            # Pre-calculate solar positions once
            solpos = pvlib.solarposition.get_solarposition(
                time=self.weather.index,
                latitude=self.cluster.lat,
                longitude=self.cluster.lon
            )

            # First pass: collect all POA values to determine global min/max
            all_values = []
            for cluster_id in cluster_ids:
                try:
                    csv_path = self.find_csv_for_cluster(self.cluster.gpkg_path, cluster_id)
                    temp_cluster = Cluster(
                        cluster_id=cluster_id,
                        gpkg_path=self.cluster.gpkg_path,
                        csv_path=csv_path,
                        lat=self.cluster.lat,
                        lon=self.cluster.lon,
                        simulation_time=self.cluster.simulation_time,
                        time_zone=self.cluster.time_zone
                    )
                    _, values = self._get_poa_samples(cluster=temp_cluster, solpos=solpos)
                    all_values.extend(values)
                except Exception as e:
                    print(f"Error processing cluster {cluster_id}: {str(e)[:100]}")
                    continue

            if not all_values:
                print("No valid POA values found")
                return

            # Determine global min/max for consistent color scaling
            global_min = min(all_values)
            global_max = max(all_values)
            levels = np.linspace(global_min, global_max, 20)

            # Second pass: actual plotting with consistent scale
            for cluster_id in cluster_ids:
                try:
                    csv_path = self.find_csv_for_cluster(self.cluster.gpkg_path, cluster_id)
                    temp_cluster = Cluster(
                        cluster_id=cluster_id,
                        gpkg_path=self.cluster.gpkg_path,
                        csv_path=csv_path,
                        lat=self.cluster.lat,
                        lon=self.cluster.lon,
                        simulation_time=self.cluster.simulation_time,
                        time_zone=self.cluster.time_zone
                    )
                    points, values = self._get_poa_samples(cluster=temp_cluster, solpos=solpos)
                    
                    # Plot with consistent scale
                    x_min, y_min, x_max, y_max = temp_cluster.geometry.bounds
                    xi, yi = np.meshgrid(
                        np.linspace(x_min, x_max, 200),
                        np.linspace(y_min, y_max, 200)
                    )
                    rbf = Rbf(points[:,0], points[:,1], values, function='thin_plate')
                    zi = rbf(xi, yi)
                    
                    mask = np.array([[not temp_cluster.geometry.contains(Point(x, y)) 
                                    for x, y in zip(xi.ravel(), yi.ravel())]]).reshape(xi.shape)
                    zi[mask] = np.nan

                    cmap = LinearSegmentedColormap.from_list('thermal', ['#1a2c8b', '#ffffff', '#a51700'])
                    contour = ax.contourf(xi, yi, zi, levels=levels, cmap=cmap, alpha=0.7)
                    
                    # Add cluster border
                    if isinstance(temp_cluster.geometry, Polygon):
                        x, y = temp_cluster.geometry.exterior.xy
                        ax.plot(x, y, 'k-', linewidth=0.8)
                    else:
                        for poly in temp_cluster.geometry.geoms:
                            x, y = poly.exterior.xy
                            ax.plot(x, y, 'k-', linewidth=0.8)

                except Exception as e:
                    print(f"Error plotting cluster {cluster_id}: {str(e)[:100]}")
                    continue

            # Add single colorbar for all clusters
            cbar = plt.colorbar(contour, ax=ax, label='POA Anual (kWh/m¬≤)')
            plt.title('All Clusters Combined - POA Radiation (Consistent Scale)')
            plt.tight_layout()
            plt.show()
            
        except Exception as e:
            print(f"Error processing GPKG: {str(e)}")
            raise

    def plot_incident_vs_produced(self):
        """
        Compara la radiaci√≥ incident (POA) amb l'energia produ√Øda pel cl√∫ster.
        Mostra un gr√†fic de barres amb kWh/m¬≤ anuals.
        """
        import matplotlib.pyplot as plt

        if not hasattr(self, 'poa_global') or not hasattr(self, 'ac'):
            print("‚ö†Ô∏è Primer has de simular almenys un panell amb simulate_panel_optimized().")
            return

        # Radiaci√≥ incident total (POA) [kWh/m¬≤]
        poa_energy_kwh_m2 = self.poa_global.sum() * self.dt_h / 1000.0

        # Energia produ√Øda total AC [kWh/m¬≤] (considerant superf√≠cie de panell)
        ac_energy_kwh_m2 = self.ac.sum() * self.dt_h / 1000.0 / self.panel_area_m2

        # Efici√®ncia global
        efficiency = ac_energy_kwh_m2 / poa_energy_kwh_m2 * 100 if poa_energy_kwh_m2 > 0 else 0

        # Plot
        labels = ["Radiaci√≥ incident (POA)", "Energia produ√Øda (AC)"]
        values = [poa_energy_kwh_m2, ac_energy_kwh_m2]
        colors = ["orange", "green"]

        plt.figure(figsize=(7, 6))
        bars = plt.bar(labels, values, color=colors, alpha=0.8)
        plt.ylabel("kWh/m¬≤ (anuals)")
        plt.title("Comparaci√≥ radiaci√≥ incident vs. producci√≥ AC\n"
                f"Efici√®ncia global: {efficiency:.1f}%")

        # Afegir valors damunt de les barres
        for bar, val in zip(bars, values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height()*1.01,
                    f"{val:.1f}", ha="center", va="bottom", fontsize=10)

        plt.grid(axis="y", linestyle="--", alpha=0.5)
        plt.show()

    def save_cluster_heatmap_png(self, cluster_obj, output_path: str, global_norm=None, cmap=None):
        """
        Genera y guarda un heatmap de POA para un cl√∫ster espec√≠fico.
        """
        print(f"    > Generando Heatmap PNG para Cl√∫ster {cluster_obj.id}...")
        try:
            # 1. Obtener datos de POA (como en tu funci√≥n plot_total_POA)
            points, values = self._get_poa_samples(cluster=cluster_obj, max_points=1000) # L√≠mite de 1000 puntos para rapidez
            if len(values) == 0:
                print(f"    > Advertencia: No se generaron valores de POA para el heatmap.")
                return

            # 2. Crear la figura
            fig, ax = plt.subplots(figsize=(8, 6))
            
            # 3. Interpolar y dibujar (usando tu l√≥gica de _plot_single_heatmap)
            x_min, y_min, x_max, y_max = cluster_obj.geometry.bounds
            xi, yi = np.meshgrid(
                np.linspace(x_min, x_max, 150), # 150x150 de resoluci√≥n
                np.linspace(y_min, y_max, 150)
            )
            rbf = Rbf(points[:,0], points[:,1], values, function='thin_plate')
            zi = rbf(xi, yi)
            
            mask = np.array([[not cluster_obj.geometry.contains(Point(x, y)) 
                            for x, y in zip(xi.ravel(), yi.ravel())]]).reshape(xi.shape)
            zi[mask] = np.nan

            # 4. Usar el colormap (el de tu TFG o uno est√°ndar)
            if cmap is None:
                cmap = LinearSegmentedColormap.from_list('thermal', ['#0000FF', '#FF0000', '#FFFF00'])
            if global_norm is None:
                global_norm = Normalize(vmin=min(values), vmax=max(values))

            contour = ax.contourf(xi, yi, zi, levels=20, cmap=cmap, norm=global_norm, alpha=0.9)
            
            # Dibujar el borde del cl√∫ster
            if isinstance(cluster_obj.geometry, Polygon):
                x, y = cluster_obj.geometry.exterior.xy
                ax.plot(x, y, 'k-', linewidth=0.8)
            else:
                for poly in cluster_obj.geometry.geoms:
                    x, y = poly.exterior.xy
                    ax.plot(x, y, 'k-', linewidth=0.8)
            
            # 5. A√±adir T√≠tulo y Guardar
            ax.set_title(f"Heatmap POA - Cl√∫ster {cluster_obj.id}\nEdificio {os.path.basename(os.path.dirname(os.path.dirname(cluster_obj.gpkg_path)))}")
            ax.set_aspect('equal')
            ax.set_xlabel("X")
            ax.set_ylabel("Y")
            plt.colorbar(contour, ax=ax, label='POA Anual (kWh/m¬≤)')
            
            fig.savefig(output_path, dpi=150, bbox_inches='tight') # dpi=150 es bueno para informes
            plt.close(fig) # ¬°MUY IMPORTANTE para liberar memoria!
            
        except Exception as e:
            plt.close('all')
            print(f"    > ‚ùå Error al guardar heatmap: {e}")

    def save_cluster_summary_csv(self, cluster_obj, panel_data_df: pd.DataFrame, output_path: str):
        """
        Calcula la radiaci√≥n incidente vs. producida y guarda un CSV de resumen.
        """
        print(f"    > Generando Resumen CSV para Cl√∫ster {cluster_obj.id}...")
        try:
            # 1. Calcular Radiaci√≥n Incidente (POA) Media del Cl√∫ster
            # (Usamos los puntos de shading, no los paneles)
            points, values_poa = self._get_poa_samples(cluster=cluster_obj, max_points=500)
            poa_media_kwh_m2 = np.mean(values_poa) if len(values_poa) > 0 else 0.0

            # 2. Calcular Energ√≠a Producida (desde el CSV de paneles)
            # Aseguramos que las columnas est√©n en min√∫sculas
            panel_data_df = panel_data_df.rename(columns={col: col.lower() for col in panel_data_df.columns})
            
            energia_total_kwh = panel_data_df['energy_annual_kwh'].sum()
            energia_media_kwh_panel = panel_data_df['energy_annual_kwh'].mean()
            num_paneles = len(panel_data_df)
            
            # 3. Crear el DataFrame de resumen
            summary_data = {
                'cluster_id': cluster_obj.id,
                'numero_paneles': num_paneles,
                'energia_total_producida_kwh': energia_total_kwh,
                'energia_media_por_panel_kwh': energia_media_kwh_panel,
                'radiacion_incidente_media_kwh_m2': poa_media_kwh_m2
            }
            summary_df = pd.DataFrame([summary_data])
            
            # 4. Guardar en CSV
            summary_df.to_csv(output_path, sep=';', index=False, encoding='utf-8-sig')

        except Exception as e:
            print(f"    > ‚ùå Error al guardar resumen CSV: {e}")



    def process_all_clusters(self, gpkg_path, lat, lon, simulation_time=10, time_zone="Europe/Madrid"):
        

        """Process all clusters in a building and return results without plotting"""
        gdf = gpd.read_file(gpkg_path)
        cluster_ids = gdf['cluster'].unique() if 'cluster' in gdf.columns else [1]

        all_results = []
        all_geometries = []

        for cluster_id in cluster_ids:
            try:
                # 1) Load cluster data
                csv_path = self.find_csv_for_cluster(gpkg_path, cluster_id)
                cluster_obj = Cluster(cluster_id, gpkg_path, csv_path, lat, lon, simulation_time, time_zone)

                # 2) Panel placement
                optimizer = SolarPanelOptimizer(cluster_obj)
                panels = optimizer.optimize_placement()

                # 3) Point-panel association
                associator = PanelPointAssociator(cluster_obj, panels)

                # 4) Calculate tilts
                tilt_opt = TiltOptimizer(cluster_obj, associator.panel_point_details)
                tilt_results = tilt_opt.compute_optimal_orientation()

                # 5) PVlib simulation
                pvlib_sim = PVlibSimulator(cluster_obj, tilt_results, associator.panel_point_details)

                for pid in range(len(panels)):
                    res = pvlib_sim.simulate_panel_optimized(pid)
                    if res:
                        # Add required fields
                        res["cluster_id"] = cluster_id
                        res["geometry"] = panels[pid]
                        res["energy_annual_kwh"] = res.get("total_energy_kwh", None)

                        # Filter monthly fields
                        monthly_fields = {
                            k: v for k, v in res.items()
                            if k.startswith("energy_kwh_month_")
                        }

                        # Sort by month
                        monthly_fields = dict(sorted(
                            monthly_fields.items(),
                            key=lambda x: int(x[0].split('_')[-1])
                        ))

                        # Build final record
                        record = {
                            "panel_id": res.get("panel_id"),
                            "cluster_id": cluster_id,
                            "tilt_deg": res.get("tilt_deg", 0),
                            "point_id": res.get("point_id", ""),
                            "energy_annual_kwh": res.get("energy_annual_kwh"),
                            **res.get("monthly_panel_dict", {}),
                            **monthly_fields
                        }
                        record["geometry"] = res.get("geometry")
                        all_results.append(record)

                all_geometries.append(cluster_obj.geometry)

            except Exception as e:
                print(f"‚ùå Error processing cluster {cluster_id}: {str(e)[:100]}")
                continue

        if not all_results:
            print("‚ö†Ô∏è No results generated.")
            return None, None

        return pd.DataFrame(all_results), all_geometries

    def save_to_csv(self, df, gpkg_path):
        """Save results to CSV file"""
        if df is None:
            print("‚ö†Ô∏è No data to save")
            return

        # Reorder columns: metadata first, then months
        meta_cols = ["panel_id", "cluster_id", "tilt_deg", "point_id", "energy_annual_kwh"]
        month_cols = sorted([c for c in df.columns if c.startswith("energy_kwh_month_")])
        
        df = df[meta_cols + month_cols]
        
        # Format numbers for Excel
        for col in df.columns:
            if pd.api.types.is_numeric_dtype(df[col]):
                df[col] = df[col].apply(lambda x: str(x).replace('.', ',') if pd.notnull(x) else '')
        
        # Save with ; separator
        building_id = os.path.basename(os.path.dirname(os.path.dirname(gpkg_path)))
        csv_filename = f"Results_{building_id}.csv"
        df.to_csv(csv_filename, sep=';', index=False)
        print(f"‚úÖ CSV saved for Excel: {csv_filename}")

    def plot_results(self, df, geometries, use_m2=False):
        """Plot the results"""
        if df is None or not geometries:
            print("‚ö†Ô∏è No data to plot")
            return

        energies = df["energy_annual_kwh"].dropna().tolist()
        if not energies:
            print("‚ö†Ô∏è No energy data to plot")
            return

        # Create colormap
        norm = Normalize(vmin=min(energies), vmax=max(energies))
        colors = [
            (0, 0, 1),       # Blue
            (0.5, 0, 0.5),   # Purple
            (1, 0, 0),       # Red
            (1, 1, 0)        # Yellow
        ]
        cmap = LinearSegmentedColormap.from_list('blue_purple_red_yellow', colors, N=256)

        # Create figure
        fig, ax = plt.subplots(figsize=(14, 10))
        ax.set_aspect("equal")

        # Plot clusters as background
        for geom in geometries:
            if isinstance(geom, Polygon):
                x, y = geom.exterior.xy
                ax.fill(x, y, alpha=0.3, color="lightblue")
            else:
                for poly in geom.geoms:
                    x, y = poly.exterior.xy
                    ax.fill(x, y, alpha=0.3, color="lightblue")

        # Plot panels colored by energy
        for _, row in df.iterrows():
            energy_val = row["energy_annual_kwh"]
            geom = row["geometry"]
            if pd.notna(energy_val) and isinstance(geom, Polygon):
                color = cmap(norm(energy_val))
                x, y = geom.exterior.xy
                ax.fill(x, y, alpha=0.8, color=color)

        # Add colorbar
        sm = cm.ScalarMappable(norm=norm, cmap=cmap)
        sm.set_array([])
        label = "Annual energy (kWh/m¬≤)" if use_m2 else "Annual energy (kWh)"
        plt.colorbar(sm, ax=ax, label=label)

        plt.title("Annual energy production - All panels")
        plt.xlabel("X")
        plt.ylabel("Y")
        plt.grid(True, linestyle="--", alpha=0.3)
        plt.show()

    def process_all_clusters_and_plot(self, gpkg_path, lat, lon, use_m2=False, simulation_time=10, time_zone="Europe/Madrid"):
        """Complete processing pipeline"""
        # Process data
        df, geometries = self.process_all_clusters(gpkg_path, lat, lon, simulation_time, time_zone)
        
        # Save results
        if df is not None:
            self.save_to_csv(df, gpkg_path)
        
        # Plot results
        self.plot_results(df, geometries, use_m2)
        
        return df


class ProjectRunner:
    def plot_all_buildings_side_by_side(self, base_dir="TFG/Dades/Edificis mostra TFG", 
                                        lat=41.38879, lon=2.15899, 
                                        simulation_time=10, time_zone="Europe/Madrid",
                                        use_m2=False, max_per_figure=12):
        import glob
        from matplotlib.colors import Normalize, LinearSegmentedColormap
        from matplotlib import cm
        import math
        from matplotlib.gridspec import GridSpec

        building_results = {}
        start_time = time.time()  # ‚è±Ô∏è Tiempo global

        # --- Process each building ---
        for gpkg_path in glob.glob(os.path.join(base_dir, "*/Plane Identification/*.gpkg")):
            building_id = os.path.basename(os.path.dirname(os.path.dirname(gpkg_path)))
            start_time_building = time.time()  # ‚è±Ô∏è Tiempo por edificio
            try:
                gdf = gpd.read_file(gpkg_path)
                if len(gdf) == 0:
                    print(f"‚ö†Ô∏è No clusters found in building {building_id}")
                    continue
                
                # Procesar todos los clusters
                temp_cluster_id = gdf['cluster'].iloc[0] if 'cluster' in gdf.columns else 1
                csv_path = self.find_csv_for_cluster(gpkg_path, temp_cluster_id)
                temp_cluster = Cluster(temp_cluster_id, gpkg_path, csv_path, lat, lon, simulation_time, time_zone)

                simulator = PVlibSimulator(
                    cluster=temp_cluster,
                    tilt_dict={},
                    panel_point_details=[],
                    test_mode=False
                )

                # Procesar y guardar
                df, geometries = self.process_and_save_building(simulator, gpkg_path, building_id, 
                                                            lat, lon, simulation_time, time_zone)

                if df is not None:
                    building_results[building_id] = (df, geometries)

                elapsed_building = time.time() - start_time_building
                print(f"‚è±Ô∏è Tiempo en procesar edificio {building_id}: {elapsed_building:.2f} segundos")

            except Exception as e:
                print(f"‚ùå Error procesando edificio {building_id}: {str(e)[:200]}")
        
        if not building_results:
            print("‚ö†Ô∏è No se generaron resultados para ning√∫n edificio.")
            return
        
        # --- Global color normalization ---
        energies = []
        for df, _ in building_results.values():
            if "energy_annual_kwh" in df.columns:
                vals = df["energy_annual_kwh"].dropna().tolist()
                energies.extend(vals)
        if not energies:
            print("‚ö†Ô∏è No hay datos de energ√≠a para graficar.")
            return

        vmin, vmax = min(energies), max(energies)
        norm = Normalize(vmin=vmin, vmax=vmax)
        colors = [(0, 0, 1), (0.5, 0, 0.5), (1, 0, 0), (1, 1, 0)]
        cmap = LinearSegmentedColormap.from_list("blue_purple_red_yellow", colors, N=256)

        # ‚≠ê‚≠ê‚≠ê DIVIDIR ELS EDIFICIS EN GRUPS ‚≠ê‚≠ê‚≠ê
        n_buildings = len(building_results)
        building_groups = []
        for i in range(0, n_buildings, max_per_figure):
            building_groups.append(dict(list(building_results.items())[i:i+max_per_figure]))

        # Crear una figura per cada grup
        figures = []  # üëà Guardar refer√®ncies a les figures
        for group_idx, group_results in enumerate(building_groups):
            n_buildings_group = len(group_results)
            ncols = min(3, n_buildings_group)
            nrows = math.ceil(n_buildings_group / ncols)
            
            fig = plt.figure(figsize=(6*ncols + 1, 6*nrows))
            gs = GridSpec(nrows, ncols + 1, width_ratios=[1]*ncols + [0.05], 
                        wspace=0.3, hspace=0.4)
            
            # --- Plot each building ---
            for i, (building_id, (df, geometries)) in enumerate(group_results.items()):
                row = i // ncols
                col = i % ncols
                
                ax = fig.add_subplot(gs[row, col])
                ax.set_aspect("equal")
                
                # clusters (azul claro)
                for geom in geometries:
                    if isinstance(geom, Polygon):
                        x, y = geom.exterior.xy
                        ax.fill(x, y, alpha=0.3, color="lightblue")
                    else:
                        for poly in geom.geoms:
                            x, y = poly.exterior.xy
                            ax.fill(x, y, alpha=0.3, color="lightblue")

                # panels (coloreados por energ√≠a)
                for _, row_data in df.iterrows():
                    energy_val = row_data.get("energy_annual_kwh")
                    geom = row_data.get("geometry")
                    if pd.notna(energy_val) and isinstance(geom, Polygon):
                        color = cmap(norm(energy_val))
                        x, y = geom.exterior.xy
                        ax.fill(x, y, alpha=0.8, color=color)
                
                ax.set_title(f"Edificio {building_id}", fontsize=14)
                ax.set_xlabel("X")
                ax.set_ylabel("Y")
                ax.grid(True, linestyle="--", alpha=0.3)

            # --- Ocultar eixos sobrants ---
            for i in range(len(group_results), nrows * ncols):
                row = i // ncols
                col = i % ncols
                ax = fig.add_subplot(gs[row, col])
                ax.set_visible(False)

            # --- Barra de colors ---
            cbar_ax = fig.add_subplot(gs[:, -1])
            sm = cm.ScalarMappable(norm=norm, cmap=cmap)
            sm.set_array([])
            
            label = "Energ√≠a anual (kWh/m¬≤)" if use_m2 else "Energ√≠a anual (kWh)"
            cbar = fig.colorbar(sm, cax=cbar_ax)
            cbar.set_label(label, fontsize=12)
            cbar.ax.tick_params(labelsize=10)

            plt.suptitle(f"Edificis {group_idx*max_per_figure + 1}-{min((group_idx+1)*max_per_figure, n_buildings)} de {n_buildings}", fontsize=16)
            plt.tight_layout()
            
            # Guardar figura
            plt.savefig(f"edificis_grup_{group_idx+1}.png", dpi=300, bbox_inches='tight')
            figures.append(fig)  # üëà Guardar la figura
            # ‚ö†Ô∏è NO posar plt.show() aqu√≠!

        # üëá MOSTRAR TOT AL FINAL (opcional)
        elapsed = time.time() - start_time
        print(f"‚è±Ô∏è Tiempo total plot_all_buildings_side_by_side: {elapsed:.2f} segundos")
        plt.show()

        return figures
       
    def process_and_save_building(self, simulator, gpkg_path, building_id, lat, lon, simulation_time, time_zone):
        """
        Processa TOTS els clusters d'un edifici i GUARDA els resultats a la carpeta 'Resultats'
        """
        try:
            # Procesar todos los clusters (esto ya lo haces)
            df, geometries = simulator.process_all_clusters(
                gpkg_path=gpkg_path,
                lat=lat,
                lon=lon,
                simulation_time=simulation_time,
                time_zone=time_zone
            )
            
            if df is not None and not df.empty:
                # CREAR CARPETA Resultats (esto ya lo haces)
                building_root = os.path.dirname(os.path.dirname(gpkg_path))
                results_dir = os.path.join(building_root, "Resultats")
                os.makedirs(results_dir, exist_ok=True)
                
                # Guardar CSV principal (esto ya lo haces)
                main_csv_path = os.path.join(results_dir, f"resultats_{building_id}.csv")
                df.to_csv(main_csv_path, sep=';', index=False, encoding='utf-8-sig')
                print(f"‚úÖ Resultats CSV guardats: {main_csv_path}")
                
                # --- BUCLE MODIFICADO ---
                # Guardar CSV y A√ëADIR HEATMAP + RESUMEN
                for cluster_id in df['cluster_id'].unique():
                    cluster_df = df[df['cluster_id'] == cluster_id]
                    
                    # 1. Guardar CSV del cluster (Tu c√≥digo)
                    cluster_csv_path = os.path.join(results_dir, f"cluster_{cluster_id}.csv")
                    cluster_df.to_csv(cluster_csv_path, sep=';', index=False, encoding='utf-8-sig')
                    print(f"  ‚úÖ Cluster {cluster_id} CSV guardat")

                    # --- ¬°¬°AQU√ç A√ëADES LO NUEVO!! ---
                    try:
                        # 2. Cargar el objeto Cluster (necesario para shading y geometr√≠a)
                        csv_shading_path = self.find_csv_for_cluster(gpkg_path, cluster_id)
                        cluster_obj = Cluster(
                            cluster_id=cluster_id,
                            gpkg_path=gpkg_path,
                            csv_path=csv_shading_path,
                            lat=lat, lon=lon, 
                            simulation_time=simulation_time, time_zone=time_zone
                        )
                        
                        # 3. Guardar el Heatmap PNG
                        heatmap_path = os.path.join(results_dir, f"heatmap_cluster_{cluster_id}.png")
                        simulator.save_cluster_heatmap_png(cluster_obj, heatmap_path)
                        print(f"  ‚úÖ Cluster {cluster_id} Heatmap PNG guardat")

                        # 4. Guardar el Resumen CSV
                        summary_path = os.path.join(results_dir, f"summary_cluster_{cluster_id}.csv")
                        simulator.save_cluster_summary_csv(cluster_obj, cluster_df, summary_path)
                        print(f"  ‚úÖ Cluster {cluster_id} Resumen CSV guardat")

                    except Exception as e:
                        print(f"  ‚ùå Error al generar archivos extra para cluster {cluster_id}: {e}")
                
                # Guardar GPKG de paneles (Tu c√≥digo)
                self.save_cluster_gpkg(simulator, results_dir, building_id)
                
                return df, geometries
            
        except Exception as e:
            print(f"‚ùå Error processant edifici {building_id}: {e}")
            return None, None

    def find_csv_for_cluster(self, gpkg_path, cluster_id):
        """Find CSV with proper path handling"""
        # Go up one level from Plane Identification to building folder
        building_root = os.path.dirname(os.path.dirname(gpkg_path))
        csv_dir = os.path.join(building_root, "Shading")
        expected_csv = f"{cluster_id}.csv"
        csv_path = os.path.normpath(os.path.join(csv_dir, expected_csv))
        
        if os.path.exists(csv_path):
            return csv_path
        
        # Try alternative names
        for alt_name in [f"cluster_{cluster_id}.csv", f"Cluster{cluster_id}.csv"]:
            alt_path = os.path.join(csv_dir, alt_name)
            if os.path.exists(alt_path):
                return alt_path
        
        raise FileNotFoundError(f"No CSV found for cluster {cluster_id} in {csv_dir}")
    
    def save_cluster_gpkg(self, simulator, results_folder, building_id):
        import geopandas as gpd
        import os

        os.makedirs(results_folder, exist_ok=True)

        # Llegir tots els clusters del GPKG original
        gdf_original = gpd.read_file(simulator.cluster.gpkg_path)
        
        # Crear un GeoDataFrame amb TOTS els panels optimitzats
        all_panels_gdf = gpd.GeoDataFrame()
        
        # Processar cada cluster
        for cluster_id in gdf_original['cluster'].unique() if 'cluster' in gdf_original.columns else [1]:
            try:
                # Crear el cluster object
                csv_path = self.find_csv_for_cluster(simulator.cluster.gpkg_path, cluster_id)
                cluster_obj = Cluster(cluster_id, simulator.cluster.gpkg_path, csv_path, 
                                    simulator.cluster.lat, simulator.cluster.lon, 
                                    simulator.cluster.simulation_time, simulator.cluster.time_zone)
                
                # Optimitzar panells per aquest cluster
                optimizer = SolarPanelOptimizer(cluster_obj)
                panels = optimizer.optimize_placement()
                
                if not panels:
                    print(f"‚ö†Ô∏è No hi ha panells per al cluster {cluster_id}")
                    continue
                associator = PanelPointAssociator(cluster_obj, panels)
                tilt_optimizer = TiltOptimizer(cluster_obj, associator.panel_point_details)
                tilt_results = tilt_optimizer.compute_optimal_orientation()
                # Crear GeoDataFrame per aquest cluster
                cluster_data = []
                for panel_id, panel_geom in enumerate(panels):
                    # Obtenir el tilt per aquest panel
                    tilt = tilt_results.get(panel_id, "NO √öTIL")
                    
                    cluster_data.append({
                        'panel_id': panel_id,
                        'cluster_id': cluster_id,
                        'building_id': building_id,
                        'tilt_deg': tilt if isinstance(tilt, (int, float)) else None,
                        'tilt_status': "UTIL" if isinstance(tilt, (int, float)) else "NO_UTIL",
                        'geometry': panel_geom
                    })
                cluster_gdf = gpd.GeoDataFrame(cluster_data, geometry='geometry', crs=gdf_original.crs)
                all_panels_gdf = pd.concat([all_panels_gdf, cluster_gdf], ignore_index=True)
                
                print(f"‚úÖ Cluster {cluster_id}: {len(panels)} panells optimitzats")
                
            except Exception as e:
                print(f"‚ùå Error processant cluster {cluster_id}: {e}")
                continue
        
        # Guardar tots els panels en un sol GPKG
        if not all_panels_gdf.empty:
            # Guardar per building
            building_gpkg_path = os.path.join(results_folder, f"panels_{building_id}.gpkg")
            all_panels_gdf.to_file(building_gpkg_path, driver="GPKG")
            print(f"‚úÖ GeoPackage guardat: {building_gpkg_path} ({len(all_panels_gdf)} panells)")
            
            # Guardar per clusters individuals
            for cluster_id in all_panels_gdf['cluster_id'].unique():
                cluster_gdf = all_panels_gdf[all_panels_gdf['cluster_id'] == cluster_id]
                cluster_gpkg_path = os.path.join(results_folder, f"panels_cluster_{cluster_id}.gpkg")
                cluster_gdf.to_file(cluster_gpkg_path, driver="GPKG")
                print(f"  ‚úÖ Cluster {cluster_id}: {len(cluster_gdf)} panells")
        
        return all_panels_gdf
  

import folium
import geopandas as gpd
import pandas as pd
import os
import glob
import re
import json
import topojson 
from folium.features import TopoJson
from branca.colormap import LinearColormap
import matplotlib.pyplot as plt
from io import BytesIO
import base64
from shapely.geometry import Polygon

class FoliumMapGenerator:
    """
    Genera un mapa donde cada EDIFICIO tiene un popup con Men√∫ Lateral.
    Incluye pesta√±a de 'Visi√≥n General' con todo el edificio y pesta√±as por Tejado.
    """
    
    def __init__(self, main_project_dir: str):
        self.main_project_dir = os.path.abspath(main_project_dir)
        self.lista_master_paneles = [] 
        self.lista_master_techos = [] 
        self.master_data_dict = {} 
        self.crs_original = None
        self.join_key = None 
        self.colormap = None
        self.norm = None 
        print(f"Map Generator: Buscando edificios en: {self.main_project_dir}")

    # --- 1. GR√ÅFICO MENSUAL ---
    def _create_monthly_plot(self, cluster_data: pd.DataFrame) -> str:
        try:
            cluster_data = cluster_data.rename(columns={col: col.lower() for col in cluster_data.columns})
            month_cols = [f'energy_kwh_month_{m:02d}' for m in range(1, 13)]
            if not all(col in cluster_data.columns for col in month_cols): return "<p>Sin datos mensuales.</p>"
            monthly = cluster_data[month_cols].sum()
            monthly.index = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']
            
            fig, ax = plt.subplots(figsize=(5.0, 3.0), dpi=100) 
            monthly.plot(kind='bar', ax=ax, color='#003366', zorder=3, width=0.7)
            ax.set_ylabel("Energ√≠a (kWh)", fontsize=9)
            ax.tick_params(axis='x', labelsize=9, rotation=45)
            ax.grid(True, linestyle='--', alpha=0.5, zorder=0)
            fig.tight_layout()
            
            buf = BytesIO()
            fig.savefig(buf, format='png')
            plt.close(fig) 
            data = base64.b64encode(buf.getvalue()).decode('utf-8')
            return f'<img src="data:image/png;base64,{data}" alt="Gr√°fico mensual">'
        except: return "<p>Error gr√°fico mensual.</p>"

    # --- 2. CARGAR IMAGEN HEATMAP ---
    def _image_to_base64(self, file_path: str) -> str:
        """Converteix una imatge a format base64 per incrustar-la en HTML."""
        if not os.path.exists(file_path):
            # Aquesta l√≠nia evita l'error TypeError
            return f"<p style='color:#999;font-size:10px;text-align:center;'>‚ö†Ô∏è Imatge {os.path.basename(file_path)} no trobada.</p>"
        
        try:
            with open(file_path, "rb") as image_file:
                encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
            style = "width:100%; border-radius:5px; margin-top:5px; display:block;"
            return f'<img src="data:image/png;base64,{encoded_string}" style="{style}">'
        except Exception as e:
            return f"<p style='color:red;font-size:10px;'>Error carregant imatge: {e}</p>"

    def _create_panel_plot(self, panel_gdf: gpd.GeoDataFrame, cluster_geom: Polygon, is_overview=False) -> str:
        """
        Versi√≥n FINAL: 
        1. Corrige el problema de gr√°ficos en blanco usando adjustable='box'.
        2. Restaura la escala de colores Azul-Rojo-Amarillo.
        3. Mantiene la detecci√≥n autom√°tica de Grados/Metros.
        """
        import matplotlib.pyplot as plt
        from matplotlib.colors import LinearSegmentedColormap
        from io import BytesIO
        import base64
        import math

        # Limpieza inicial
        plt.close('all')

        try:
            # 1. Configurar figura
            fig = plt.figure(figsize=(4, 3), dpi=80)
            ax = fig.add_subplot(111)

            # 2. Dibujar Fondo (Techo)
            geo_ok = False
            if cluster_geom is not None and not cluster_geom.is_empty:
                try:
                    gs = gpd.GeoSeries([cluster_geom])
                    if gs.crs is None: gs.crs = "EPSG:4326"
                    
                    c_fondo = "#f0f0f0" if is_overview else "#dbeafe"
                    gs.plot(ax=ax, color=c_fondo, edgecolor='#999999', alpha=0.5, linewidth=1)
                    geo_ok = True
                except Exception:
                    pass

            # 3. Dibujar Paneles con Color Correcto
            if panel_gdf is not None and not panel_gdf.empty:
                try:
                    p = panel_gdf.copy()
                    if p.crs is None: p.set_crs("EPSG:4326", allow_override=True)
                    
                    # Alinear CRS
                    if geo_ok and hasattr(gs, 'crs') and gs.crs != p.crs:
                        p = p.to_crs(gs.crs)
                    
                    # Definir Mapa de Color Personalizado (Azul -> Rojo -> Amarillo)
                    colors = ["#0000FF", "#FF0000", "#FFFF00"]
                    custom_cmap = LinearSegmentedColormap.from_list("custom_cmap", colors)

                    col_e = next((c for c in p.columns if 'energy' in c.lower()), None)
                    if col_e:
                        vmin, vmax = p[col_e].min(), p[col_e].max()
                        if vmin == vmax: vmax += 1 # Evitar error de rango nulo
                        
                        p.plot(ax=ax, column=col_e, cmap=custom_cmap, vmin=vmin, vmax=vmax, 
                               edgecolor='black', linewidth=0.1)
                    else:
                        p.plot(ax=ax, color='blue', edgecolor='black', linewidth=0.1)
                except Exception:
                    pass

            # 4. CORRECCI√ìN DE L√çMITES (Geometr√≠a Segura)
            x_min, x_max = ax.get_xlim()
            y_min, y_max = ax.get_ylim()
            
            w = x_max - x_min
            h = y_max - y_min

            # Detectar unidades (Grados vs Metros)
            es_grados = w < 1.0 or h < 1.0
            margen_seguridad = 1e-5 if es_grados else 1.0

            # Validaci√≥n matem√°tica
            def is_bad(n): return math.isnan(n) or math.isinf(n)
            
            if is_bad(x_min) or is_bad(x_max) or is_bad(y_min) or is_bad(y_max):
                x_min, x_max = 0, 10
                y_min, y_max = 0, 10
            else:
                # Expandir si es muy peque√±o para dar "cuerpo" al gr√°fico
                if w < margen_seguridad:
                    cx = (x_min + x_max) / 2
                    x_min = cx - margen_seguridad
                    x_max = cx + margen_seguridad
                
                if h < margen_seguridad:
                    cy = (y_min + y_max) / 2
                    y_min = cy - margen_seguridad
                    y_max = cy + margen_seguridad

            # Aplicar l√≠mites y quitar ejes
            ax.set_xlim(x_min, x_max)
            ax.set_ylim(y_min, y_max)
            ax.set_axis_off()

            # 5. GUARDADO (Uso de 'box' para evitar blancos)
            buf = BytesIO()
            try:
                # 'box' ajusta la caja del gr√°fico a los datos, no al rev√©s.
                ax.set_aspect('equal', adjustable='box')
                fig.savefig(buf, format='png', transparent=True, pad_inches=0)
            except Exception:
                # Fallback a auto si falla la proporci√≥n
                ax.set_aspect('auto')
                buf = BytesIO()
                fig.savefig(buf, format='png', transparent=True, pad_inches=0)

            plt.close(fig)
            data = base64.b64encode(buf.getvalue()).decode('utf-8')
            
            style = "width:100%; height:auto; border-radius:4px; margin-top:5px; display:block;"
            if is_overview: style += " max-height: 250px; object-fit: contain;"
            
            return f'<img src="data:image/png;base64,{data}" style="{style}">'

        except Exception as e:
            plt.close('all')
            return f"<p style='color:orange; font-size:10px;'>Error render: {str(e)}</p>"

    def _create_colorbar(self) -> str:
        """
        Genera una barra de color (llegenda) com a imatge base64 
        usant l'escala de color global del projecte (self.colormap).
        """
        # Importacions necess√†ries (si no estan a l'inici del teu fitxer)
        import matplotlib.pyplot as plt
        from matplotlib.colors import LinearSegmentedColormap
        from io import BytesIO
        import base64
        
        cmap = self.colormap
        norm = self.norm
        
        # Comprovem que l'escala global s'hagi inicialitzat correctament
        if cmap is None or norm is None:
            # Retorna un missatge d'error o buit si no hi ha escala
            return "<p style='text-align:center; font-size:10px; color:#999;'>Llegenda no disponible (sense dades globals).</p>"

        try:
            fig, ax = plt.subplots(figsize=(6.0, 0.5)) # Figura petita i horitzontal
            
            # Creaci√≥ de la barra de color utilitzant l'escala global
            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
            sm.set_array([]) 
            
            # Dibuixem la barra de color
            cbar = fig.colorbar(sm, cax=ax, orientation='horizontal', format='%.0f')
            cbar.set_label('Energia Anual Mitjana per Panel (kWh)', fontsize=8)
            cbar.ax.tick_params(labelsize=7)
            
            plt.tight_layout(pad=0.1)

            # Convertim la figura a Base64
            buf = BytesIO()
            fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0.1, transparent=True)
            plt.close(fig) 
            data = base64.b64encode(buf.getvalue()).decode('utf-8')
            
            return f'<div style="text-align:center; padding:10px;"><img src="data:image/png;base64,{data}" style="max-width:90%; height:auto;"></div>'
            
        except Exception as e: 
            plt.close('all')
            print(f"Error generant la barra de color: {e}")
            return ""

    def _create_panel_table(self, panel_gdf: gpd.GeoDataFrame) -> str:
        if panel_gdf is None or panel_gdf.empty: return ""
        try:
            panel_gdf = panel_gdf.rename(columns={col: col.lower() for col in panel_gdf.columns})
            html = '<div class="table-container"><table class="modern-table">'
            html += '<thead><tr><th>ID</th><th>Tilt</th><th>Gen.</th></tr></thead><tbody>'
            
            id_col = self.join_key if self.join_key else 'panel_id'
            for _, row in panel_gdf.iterrows():
                pid = row.get(id_col, 'N/A')
                tilt = row.get('tilt_deg', 0)
                gen = row.get('energy_annual_kwh', 0)
                html += f"<tr><td>{pid}</td><td>{tilt:.0f}¬∞</td><td>{gen:.0f}</td></tr>"
            
            html += '</tbody></table></div>'
            return html
        except: return ""

    def create_map(self, output_filename: str = "mapa_TODOS_LOS_EDIFICIOS_FINAL.html"):
        # 1. VERIFICACIONS
        if not os.path.exists(self.main_project_dir):
            print(f"‚ùå ERROR: No existe: {self.main_project_dir}")
            return

        building_folders = [f for f in glob.glob(os.path.join(self.main_project_dir, "*")) if os.path.isdir(f)]
        print(f"Encontrados {len(building_folders)} edificios.")
        original_roof_gdfs = {}

        # 2. BUCLE DE PROCESAMIENTO
        for building_path in building_folders:
            b_id = os.path.basename(building_path)
            if not b_id.isdigit(): continue
            
            # Rutas
            ROOF_GPKG_PATH = os.path.join(building_path, "Plane Identification", f"{b_id}.gpkg")
            RESULTS_DIR = os.path.join(building_path, "Resultats")

            if not os.path.exists(ROOF_GPKG_PATH) or not os.path.exists(RESULTS_DIR): continue

            # Cargar Techos
            try:
                gdf_r = gpd.read_file(ROOF_GPKG_PATH)
                gdf_r.columns = map(str.lower, gdf_r.columns)
                gdf_r['cluster'] = gdf_r['cluster'].astype(int)
                if self.crs_original is None: self.crs_original = gdf_r.crs or "EPSG:25831"
                if gdf_r.crs is None: gdf_r = gdf_r.set_crs(self.crs_original, allow_override=True)
                original_roof_gdfs[b_id] = gdf_r.copy()
            except: continue

            # Cargar Paneles
            local_panels = []
            csv_files = glob.glob(os.path.join(RESULTS_DIR, "cluster_*.csv"))
            id_extractor = re.compile(r"cluster_(\d+)\.csv")

            for csv_path in csv_files:
                try:
                    fname = os.path.basename(csv_path)
                    match = id_extractor.match(fname)
                    if not match: continue
                    c_id = int(match.group(1))
                    
                    df_d = pd.read_csv(csv_path, sep=';')
                    df_d.columns = map(str.lower, df_d.columns)
                    
                    p_gpkg = os.path.join(RESULTS_DIR, f"panels_cluster_{c_id}.gpkg")
                    if not os.path.exists(p_gpkg): p_gpkg = os.path.join(RESULTS_DIR, f"paneles_cluster_{c_id}.gpkg")
                    if not os.path.exists(p_gpkg): continue
                    
                    gdf_p = gpd.read_file(p_gpkg)
                    gdf_p.columns = map(str.lower, gdf_p.columns)
                    if gdf_p.crs is None: gdf_p = gdf_p.set_crs(self.crs_original, allow_override=True)
                    
                    self.join_key = 'panel_id'
                    if 'point_id' in df_d.columns and 'point_id' in gdf_p.columns: self.join_key = 'point_id'
                    if self.join_key not in df_d.columns or self.join_key not in gdf_p.columns: continue
                    
                    gdf_p[self.join_key] = pd.to_numeric(gdf_p[self.join_key], errors='coerce')
                    df_d[self.join_key] = pd.to_numeric(df_d[self.join_key], errors='coerce')
                    gdf_m = gdf_p.merge(df_d, on=self.join_key)
                    
                    if 'geometry_x' in gdf_m.columns:
                        if 'geometry_y' in gdf_m.columns: gdf_m = gdf_m.drop(columns=['geometry_y'])
                        gdf_m = gdf_m.rename(columns={'geometry_x': 'geometry'}).set_geometry('geometry')
                    
                    if len(gdf_m) == 0: continue
                    if 'energy_annual_kwh' not in gdf_m.columns: gdf_m['energy_annual_kwh'] = 0
                    
                    # ### !!! IMPORTANTE !!! ESTAS DOS L√çNEAS ARREGLAN EL KEYERROR ###
                    gdf_m['building_id'] = b_id
                    gdf_m['cluster_id'] = c_id 
                    # ##############################################################

                    local_panels.append(gdf_m)
                    self.master_data_dict[(b_id, c_id)] = gdf_m
                except: pass

            # Unir al edificio
            if local_panels:
                self.lista_master_paneles.extend(local_panels)
                df_all = pd.concat(local_panels)
                
                # AHORA ESTO S√ç FUNCIONAR√Å PORQUE 'cluster_id' EXISTE
                # MODIFICADO: A√±adido el c√°lculo de la MEDIA
                df_grp = df_all.groupby('cluster_id').agg(
                    numero_paneles=(self.join_key, 'count'),
                    energia_anual_kWh=('energy_annual_kwh', 'sum'),
                    energia_mitjana_kWh=('energy_annual_kwh', 'mean') # <--- NUEVO CAMPO AGREGADO
                ).reset_index().rename(columns={'cluster_id': 'cluster'})
                
                # AHORA ESTO S√ç FUNCIONAR√Å PORQUE 'cluster_id' EXISTE
                
                gdf_b = gdf_r.merge(df_grp, on='cluster', how='left')
            else:
                gdf_b = gdf_r
            
            gdf_b['building_id'] = b_id
            self.lista_master_techos.append(gdf_b)

        if not self.lista_master_techos: 
            print("‚ùå No hay datos.")
            return

        # 3. GENERAR MAPA
        print("Generando Mapa HTML...")
        gdf_TECHOS_FINAL = gpd.GeoDataFrame(pd.concat(self.lista_master_techos, ignore_index=True), crs=self.crs_original).to_crs(epsg=4326)
        
        gdf_PANEL_WEB = None
        if self.lista_master_paneles:
            gdf_PANEL_FINAL = gpd.GeoDataFrame(pd.concat(self.lista_master_paneles, ignore_index=True), crs=self.crs_original)
            gdf_PANEL_WEB = gdf_PANEL_FINAL.to_crs(epsg=4326)

        bounds = gdf_TECHOS_FINAL.total_bounds
        m = folium.Map(location=[(bounds[1]+bounds[3])/2, (bounds[0]+bounds[2])/2], zoom_start=18)
        folium.TileLayer('https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}', attr='Google', name='Google Satellite', overlay=True).add_to(m)

        # Capa Paneles
        if gdf_PANEL_WEB is not None and 'energy_annual_kwh' in gdf_PANEL_WEB.columns:
            layer_p = folium.FeatureGroup(name='Paneles', control=True).add_to(m)
            min_e, max_e = gdf_PANEL_WEB['energy_annual_kwh'].min(), gdf_PANEL_WEB['energy_annual_kwh'].max()
            if min_e == max_e: max_e += 1.0
            self.colormap = LinearColormap(['#0000FF', '#FF0000', '#FFFF00'], vmin=min_e, vmax=max_e)
            self.norm = plt.Normalize(vmin=min_e, vmax=max_e)
            self.colormap.add_to(m)
            
            # --- INSERCI√ì DE LA BARRA DE COLOR ---
            # IMPORTANT: Assegureu-vos d'haver importat 'folium' al vostre fitxer principal.
            from folium import Element 
            colorbar_html = self._create_colorbar()
            if colorbar_html:
                # Aquesta l√≠nia inyecta el HTML de la barra de color al cos del document del mapa
                Element(colorbar_html).add_to(m.get_root().html) 
            # -------------------------------------
            
            gdf_PANEL_WEB['tooltip'] = gdf_PANEL_WEB['energy_annual_kwh'].round(0)
            topo = topojson.Topology(gdf_PANEL_WEB, prevent_oversimplify=True)
            TopoJson(json.loads(topo.to_json()), 'objects.data', name='Paneles',
                style_function=lambda x: {'fillColor': self.colormap(x['properties']['energy_annual_kwh']), 'color': 'black', 'weight': 0.1, 'fillOpacity': 0.8},
                tooltip=folium.features.GeoJsonTooltip(fields=['tooltip'], aliases=['kWh/Panel:']) # MODIFICADO: Etiqueta
            ).add_to(layer_p)

        # 4. CAPA TECHOS (DISE√ëO SIDEBAR)
        layer_e = folium.FeatureGroup(name='Edificios').add_to(m)
        
        for b_id, b_data in gdf_TECHOS_FINAL.groupby('building_id'):
            
            sidebar_html = f"""
            <div class="sidebar">
                <div class="sidebar-header"><h3>Edif. {b_id}</h3><p>Selecciona Tejado:</p></div>
                <div class="btn-group">
            """
            content_html = '<div class="content-area">'
            
            # PESTA√ëA HOME
            # Preparar imagen overview
            all_panels = []
            for c_id_temp in b_data['cluster']:
                p_dat = self.master_data_dict.get((str(b_id), c_id_temp))
                if p_dat is not None: all_panels.append(p_dat)
            
            img_ov = "<p>Sin paneles</p>"
            if all_panels:
                full_gdf = pd.concat(all_panels)
                img_ov = self._create_panel_plot(full_gdf, b_data.geometry.unary_union, is_overview=True)

            t_pan = b_data['numero_paneles'].sum()
            t_en = b_data['energia_anual_kWh'].sum()
            t_avg = t_en / t_pan if t_pan > 0 else 0 # MODIFICADO: C√°lculo de la media global
            
            sidebar_html += f"""<button class="nav-btn active" onclick="openTab(event, 'home-{b_id}')">üè† Visi√≥n General</button>"""
            # MODIFICADO: Bloque de estad√≠sticas con 3 columnas (Total Paneles, Energ√≠a Total, Energ√≠a Media)
            content_html += f""" 	
            <div id="home-{b_id}" class="tab-content" style="display:block;">
                <h2 class="main-title">Resumen Global</h2>
                <div style="text-align:center; margin-bottom:20px;">{img_ov}</div>
                <div class="stats-grid" style="grid-template-columns: 1fr 1fr 1fr;">
                    <div class="stat-item"><div style="font-size:20px;color:#003366;font-weight:bold">{int(t_pan)}</div><div style="font-size:10px">PANELES</div></div>
                    <div class="stat-item"><div style="font-size:20px;color:#003366;font-weight:bold">{t_en/1000:.1f} MWh</div><div style="font-size:10px">ENERG√çA TOTAL</div></div>
                    <div class="stat-item"><div style="font-size:20px;color:#003366;font-weight:bold">{t_avg:.0f} kWh</div><div style="font-size:10px">ENERG√çA MEDIA/PANEL</div></div>
                </div>
                <p style="text-align:center; font-size:11px; color:#999; margin-top:20px;">‚¨á Selecciona un tejado para detalles ‚¨á</p>
            </div>
            """

            # PESTA√ëAS INDIVIDUALES
            for idx, row in b_data.iterrows():
                c_id = row['cluster']
                res_dir = os.path.join(self.main_project_dir, str(b_id), "Resultats")
                heat_png = os.path.join(res_dir, f"heatmap_cluster_{c_id}.png")
                
                try:
                    orig = original_roof_gdfs.get(str(b_id))
                    g_dat = orig[orig['cluster'] == c_id].iloc[0]
                    poly, area, tilt, az = g_dat.geometry, g_dat.geometry.area, g_dat.get('tilt',0), g_dat.get('azimuth',0)
                except: 
                    poly, area, tilt, az = row.geometry, 0, 0, 0

                num = row.get('numero_paneles', 0)
                if pd.isna(num) or num == 0:
                    sidebar_html += f"""<button class="nav-btn disabled">Tejado {c_id} (X)</button>"""
                else:
                    e_tot = row.get('energia_anual_kWh', 0)
                    e_avg = row.get('energia_mitjana_kWh', 0) # MODIFICADO: Lectura de la media
                    poa = 0 # Cargar poa si existe... (resumido)
                    
                    dat = self.master_data_dict.get((str(b_id), c_id))
                    
                    sidebar_html += f"""<button class="nav-btn" onclick="openTab(event, 'tab-{b_id}-{c_id}')">Tejado {c_id}</button>"""
                    # MODIFICADO: Bloque de estad√≠sticas del detalle del cl√∫ster (4 columnas)
                    content_html += f"""
                    <div id="tab-{b_id}-{c_id}" class="tab-content" style="display:none;">
                        <h3 class="main-title">Tejado {c_id} <span style="float:right;font-size:12px;color:#666">{int(num)} Paneles</span></h3>
                        <div class="stats-grid">
                            <div class="stat-item"><b>A:</b> {area:.0f}m¬≤</div>
                            <div class="stat-item"><b>T:</b> {tilt:.0f}¬∞</div>
                            <div class="stat-item"><b>E Tot:</b> {e_tot:.0f} kWh</div>
                            <div class="stat-item"><b>E Med:</b> {e_avg:.0f} kWh</div>
                        </div>
                        
                        <h4 class="sec-title">Mapa de Calor</h4> {self._image_to_base64(heat_png)}
                        <h4 class="sec-title">Disposici√≥n</h4> {self._create_panel_plot(dat, poly)}
                        
                        <h4 class="sec-title">Mensual</h4> {self._create_monthly_plot(dat)} ¬†
                        <h4 class="sec-title">Detalle Paneles</h4> {self._create_panel_table(dat)} ¬†
                        
                    </div>
                    """

            sidebar_html += "</div></div>"
            content_html += "</div>"

            full_html = f"""
            <html><head><style>
                body {{ margin:0; padding:0; font-family: 'Segoe UI', sans-serif; display: flex; width: 750px; height: 550px; }}
                .sidebar {{ width: 160px; background: #f4f4f4; border-right: 1px solid #ccc; display: flex; flex-direction: column; }}
                .sidebar-header {{ background: #003366; color: white; padding: 10px; text-align: center; }}
                .btn-group {{ padding: 10px; overflow-y: auto; flex: 1; }}
                .nav-btn {{ width: 100%; padding: 8px; margin-bottom: 5px; border: 1px solid #ddd; background: #fff; text-align: left; cursor: pointer; font-size: 11px; border-radius: 3px; }}
                .nav-btn:hover {{ background: #e9e9e9; }}
                .nav-btn.active {{ background: #003366; color: white; }}
                .nav-btn.disabled {{ color: #aaa; cursor: default; background: #f9f9f9; }}
                .content-area {{ flex: 1; padding: 20px; overflow-y: auto; background: white; }}
                .main-title {{ color: #003366; border-bottom: 2px solid #003366; margin: 0 0 10px 0; font-size: 18px; }}
                .sec-title {{ color: #004a99; border-bottom: 1px solid #eee; margin: 20px 0 5px 0; font-size: 12px; font-weight: bold; text-transform: uppercase; }}
                .stats-grid {{ display: grid; grid-template-columns: repeat(4, 1fr); gap: 8px; }}
                .stat-item {{ background: #f8f9fa; padding: 5px; border: 1px solid #eee; text-align: center; font-size: 10px; border-radius: 4px; }}
                .table-container {{ max-height: 150px; overflow-y: auto; border: 1px solid #eee; margin-top: 5px; }}
                .modern-table {{ width: 100%; border-collapse: collapse; font-size: 10px; }}
                .modern-table th {{ position: sticky; top: 0; background: #003366; color: white; padding: 5px; text-align: center; }}
                .modern-table td {{ padding: 4px; border-bottom: 1px solid #eee; text-align: center; }}
                .modern-table tr:nth-child(even) {{ background: #f8f9fa; }}
                img {{ max-width: 100%; border-radius: 4px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }}
                @keyframes fade {{ from {{opacity: 0;}} to {{opacity: 1;}} }} .tab-content {{ animation: fade 0.4s; }}
            </style>
            <script>
                function openTab(evt, id) {{
                    var cs = document.getElementsByClassName("tab-content");
                    for (var i=0; i<cs.length; i++) cs[i].style.display = "none";
                    var ls = document.getElementsByClassName("nav-btn");
                    for (var i=0; i<ls.length; i++) ls[i].className = ls[i].className.replace(" active", "");
                    document.getElementById(id).style.display = "block";
                    evt.currentTarget.className += " active";
                }}
            </script></head>
            <body>{sidebar_html}{content_html}</body></html>
            """

            if not b_data.empty:
                combined = b_data.geometry.unary_union
                iframe = folium.IFrame(full_html, width=770, height=570)
                popup = folium.Popup(iframe, max_width=770)
                folium.GeoJson(combined, style_function=lambda x: {'fillColor':'grey', 'color':'white', 'weight':1, 'fillOpacity':0.01}, popup=popup).add_to(layer_e)

        folium.LayerControl().add_to(m)
        output_path = os.path.join(self.main_project_dir, output_filename)
        m.save(output_path)
        print(f"\nüéâ Mapa guardado: {output_path}")
           
#gpkg_path="TFG/Dades/Edificis mostra TFG/672/Plane Identification/672.gpkg",
#csv_path="TFG/Dades/Edificis mostra TFG/672/Shading Optimized/2.csv",

#gpkg_path="TFG/Dades/Edificis mostra TFG/401/Plane Identification/401.gpkg",
#csv_path="TFG/Dades/Edificis mostra TFG/401/Shading Optimized/2.csv",

#gpkg_path="TFG/Dades/Edificis mostra TFG/86/Plane Identification/86.gpkg",
#csv_path="TFG/Dades/Edificis mostra TFG/86/Shading Optimized/15.csv",

#gpkg_path="TFG/Dades/Sample 54 edificis Adri√† (1)/Sample 54 edifics Adri√†/115082126/Plane Identification/115082126.gpkg",
#csv_path="TFG/Dades/Sample 54 edificis Adri√† (1)/Sample 54 edifics Adri√†/115082126/Shading/1.csv",

if __name__ == "__main__":
    # 1. Initialize Cluster 
    cluster = Cluster(
        cluster_id=1,
        gpkg_path = r"Dades\Sample 54 edificis Adri√† (1)\Sample 54 edifics Adri√†\115085475\Plane Identification\115085475.gpkg",
        csv_path=r"Dades\Sample 54 edificis Adri√† (1)\Sample 54 edifics Adri√†\115085475\Shading\1.csv",
        lat=41.38879,
        lon=2.15899,
        simulation_time=90,
        time_zone="Europe/Madrid",
        panel_w=1.0,
        panel_l=1.7,    
        sep_row=0.05,
        base_dir="Dades/Sample 54 edificis Adri√† (1)/Sample 54 edifics Adri√†"
    )
    
    # 2. Optimize Panel Placement
    optimizer = SolarPanelOptimizer(cluster)
    panels = optimizer.optimize_placement()
    #optimizer.plot_edge_start_points()

    print(f"Paneles colocados: {len(panels)}")
    print(f"√Årea total: {sum(p.area for p in panels):.2f} m¬≤")
    print("\n=== Datos del cluster ===")
    print(f"Cluster ID: {cluster.id}")
    print(f"Tipo de geometr√≠a: {cluster.geometry.geom_type}")  # Deber√≠a ser 'Polygon' o 'MultiPolygon'
    print(f"√Årea del cluster: {cluster.geometry.area:.2f} m¬≤")  # Verifica que el √°rea sea razonable


    # 3. Associate Points with Panels
    associator = PanelPointAssociator(
        cluster=cluster,
        solar_panels=panels,
        border_distance=0.4,
        near_distance=0.7,
        inner_weight=1.0,
        border_weight=0.8,
        near_weight=0.24
    )

    # 4. Calculate Optimal Tilts
    tilt_results = TiltOptimizer(cluster, associator.panel_point_details).compute_optimal_orientation()

    # 5. Initialize Simulator
    simulator = PVlibSimulator(cluster=cluster, tilt_dict=tilt_results,
                            panel_point_details=associator.panel_point_details,
                            )
    plot_tilt_results(cluster.geometry, panels, tilt_results)
    print(simulator.weather.index[0], simulator.weather.index[-1])
   
    #simulator.plot_panel_power_and_horizon(panel_id=5, fecha='1990-01-21', window_minutes=1)
    #simulator.compute_and_save_csv(filename="results450w.csv", workers=4)
    #simulator.info_important()
    #simulator.plot_total_POA()
    #simulator.plot_incident_vs_produced()

    """simulator.process_all_clusters_and_plot(
        gpkg_path=cluster.gpkg_path,
        lat=cluster.lat,
        lon=cluster.lon,
        use_m2=False,
        simulation_time=cluster.simulation_time,
        time_zone=cluster.time_zone
    )"""
    
    """runner = ProjectRunner()
    runner.plot_all_buildings_side_by_side(
        base_dir=cluster.base_dir,
        lat=cluster.lat,
        lon=cluster.lon,
        simulation_time=cluster.simulation_time,  # üëà Redueix per proves
        time_zone=cluster.time_zone
    )"""

    map_generator = FoliumMapGenerator(
        main_project_dir=cluster.base_dir
    )
    map_generator.create_map()
